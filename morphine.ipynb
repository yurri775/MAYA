{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import bz2\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Telecharger dataset\n",
    "path = kagglehub.dataset_download(\"sidharthangn/celebrity-face-dataset-augmented\")\n",
    "print(\"Dataset:\", path)\n",
    "\n",
    "# Config\n",
    "SIZE = 128\n",
    "ALPHA = 0.5\n",
    "NUM_VARIATIONS = 30  # 30 images par paire\n",
    "MIN_IMAGES_PER_PERSON = 6  # Minimum 6 images par personne\n",
    "\n",
    "# Dossiers\n",
    "OUTPUT_DIR = Path(\"./morphed_database\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "LOCAL_DATA_DIR = Path(\"./dlib_models\")\n",
    "LOCAL_DATA_DIR.mkdir(exist_ok=True)\n",
    "PREDICTOR_PATH = LOCAL_DATA_DIR / \"shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# Dlib\n",
    "if not PREDICTOR_PATH.exists():\n",
    "    print(\"Telechargement Dlib...\")\n",
    "    url = \"http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\"\n",
    "    compressed = LOCAL_DATA_DIR / \"temp.bz2\"\n",
    "    urllib.request.urlretrieve(url, compressed)\n",
    "    with bz2.BZ2File(compressed, 'rb') as f_in:\n",
    "        with open(PREDICTOR_PATH, 'wb') as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "    compressed.unlink()\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(str(PREDICTOR_PATH))\n",
    "print(\"[OK] Dlib charge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = defaultdict(list)\n",
    "for person_dir in Path(path).rglob(\"*\"):\n",
    "    if person_dir.is_dir():\n",
    "        images = list(person_dir.glob(\"*.jpg\")) + list(person_dir.glob(\"*.png\"))\n",
    "        if len(images) >= MIN_IMAGES_PER_PERSON:\n",
    "            persons[person_dir.name] = [str(img) for img in images]\n",
    "\n",
    "print(f\"\\n[OK] {len(persons)} personnes avec {MIN_IMAGES_PER_PERSON}+ images:\")\n",
    "for i, (name, imgs) in enumerate(persons.items()):\n",
    "    print(f\"   {i+1}. {name}: {len(imgs)} images\")\n",
    "\n",
    "# Calculer les stats\n",
    "n_persons = len(persons)\n",
    "n_pairs = n_persons * (n_persons - 1) // 2\n",
    "n_total_images = n_pairs * NUM_VARIATIONS\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CONFIGURATION:\")\n",
    "print(f\"   - Personnes: {n_persons}\")\n",
    "print(f\"   - Paires possibles: {n_pairs}\")\n",
    "print(f\"   - Images par paire: {NUM_VARIATIONS}\")\n",
    "print(f\"   - TOTAL IMAGES A GENERER: {n_total_images}\")\n",
    "print(f\"   - Alpha: {ALPHA} (50%)\")\n",
    "print(f\"   - Dossier sortie: {OUTPUT_DIR}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(img_gray, detector, predictor, upsample_times=0):\n",
    "    dets = detector(img_gray, upsample_times)\n",
    "    if len(dets) == 0:\n",
    "        return None\n",
    "    shape = predictor(img_gray, dets[0])\n",
    "    pts = np.zeros((68, 2), dtype=np.int32)\n",
    "    for i in range(68):\n",
    "        pts[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    return pts\n",
    "\n",
    "def add_corner_points(points, w, h):\n",
    "    corners = np.array([\n",
    "        [0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1],\n",
    "        [w // 2, 0], [w - 1, h // 2], [w // 2, h - 1], [0, h // 2]\n",
    "    ], dtype=np.int32)\n",
    "    return np.concatenate([points, corners], axis=0)\n",
    "\n",
    "def clamp_points(points, w, h):\n",
    "    pts = np.array(points, dtype=np.float32)\n",
    "    pts[:, 0] = np.clip(pts[:, 0], 0, w - 1)\n",
    "    pts[:, 1] = np.clip(pts[:, 1], 0, h - 1)\n",
    "    return pts\n",
    "\n",
    "def find_point_index(points, pt, tol=3.0):\n",
    "    pts = np.asarray(points, dtype=np.float32)\n",
    "    dists = np.linalg.norm(pts - np.asarray(pt, dtype=np.float32), axis=1)\n",
    "    idx = int(np.argmin(dists))\n",
    "    if dists[idx] <= tol:\n",
    "        return idx\n",
    "    return None\n",
    "\n",
    "def triangle_completely_inside(t, w, h):\n",
    "    for (x, y) in t:\n",
    "        if x < 0 or x >= w or y < 0 or y >= h:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def apply_affine_transform(src, src_tri, dst_tri, size):\n",
    "    warp_mat = cv2.getAffineTransform(np.float32(src_tri), np.float32(dst_tri))\n",
    "    dst = cv2.warpAffine(src, warp_mat, (int(size[0]), int(size[1])),\n",
    "                         None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "    return dst\n",
    "\n",
    "def morph_triangle(img1, img2, img_morphed, t1, t2, t_morphed, alpha):\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "    r = cv2.boundingRect(np.float32([t_morphed]))\n",
    "\n",
    "    if r1[2] <= 0 or r1[3] <= 0 or r2[2] <= 0 or r2[3] <= 0 or r[2] <= 0 or r[3] <= 0:\n",
    "        return\n",
    "\n",
    "    t1_rect = [(t1[i][0] - r1[0], t1[i][1] - r1[1]) for i in range(3)]\n",
    "    t2_rect = [(t2[i][0] - r2[0], t2[i][1] - r2[1]) for i in range(3)]\n",
    "    t_rect = [(t_morphed[i][0] - r[0], t_morphed[i][1] - r[1]) for i in range(3)]\n",
    "\n",
    "    img1_rect = img1[r1[1]:r1[1]+r1[3], r1[0]:r1[0]+r1[2]]\n",
    "    img2_rect = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]]\n",
    "\n",
    "    if img1_rect.size == 0 or img2_rect.size == 0:\n",
    "        return\n",
    "\n",
    "    size_rect = (r[2], r[3])\n",
    "\n",
    "    warp_img1 = apply_affine_transform(img1_rect, t1_rect, t_rect, size_rect)\n",
    "    warp_img2 = apply_affine_transform(img2_rect, t2_rect, t_rect, size_rect)\n",
    "\n",
    "    img_rect = (1.0 - alpha) * warp_img1 + alpha * warp_img2\n",
    "\n",
    "    mask = np.zeros((r[3], r[2]), dtype=np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(t_rect), 1.0, 16, 0)\n",
    "\n",
    "    y, x, w_rect, h_rect = r[1], r[0], r[2], r[3]\n",
    "    img_morphed[y:y+h_rect, x:x+w_rect] = img_morphed[y:y+h_rect, x:x+w_rect] * (1 - mask[:, :, None]) + img_rect * mask[:, :, None]\n",
    "\n",
    "def prepare_points_for_image(img_gray, w, h):\n",
    "    pts = get_landmarks(img_gray, detector, predictor, upsample_times=0)\n",
    "    if pts is None:\n",
    "        grid_x = np.tile(np.linspace(w*0.25, w*0.75, 17), (4,))\n",
    "        grid_y = np.repeat(np.linspace(h*0.25, h*0.75, 4), 17)\n",
    "        grid = np.vstack([grid_x[:68], grid_y[:68]]).T.astype(np.int32)\n",
    "        pts = grid\n",
    "    pts = clamp_points(pts, w, h)\n",
    "    pts = add_corner_points(pts.astype(np.int32), w, h)\n",
    "    return pts.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph_faces(img_path_a, img_path_b, alpha=0.5):\n",
    "    imgA = cv2.imread(str(img_path_a))\n",
    "    imgB = cv2.imread(str(img_path_b))\n",
    "    \n",
    "    if imgA is None or imgB is None:\n",
    "        return None\n",
    "    \n",
    "    imgA_resized = cv2.resize(imgA, (SIZE, SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "    imgB_resized = cv2.resize(imgB, (SIZE, SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    imgA_gray = cv2.cvtColor(imgA_resized, cv2.COLOR_BGR2GRAY)\n",
    "    imgB_gray = cv2.cvtColor(imgB_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    imgA_color = imgA_resized.astype(np.float32)\n",
    "    imgB_color = imgB_resized.astype(np.float32)\n",
    "\n",
    "    ptsA = prepare_points_for_image(imgA_gray, SIZE, SIZE)\n",
    "    ptsB = prepare_points_for_image(imgB_gray, SIZE, SIZE)\n",
    "\n",
    "    points_morphed = (1.0 - alpha) * ptsA + alpha * ptsB\n",
    "    points_morphed = clamp_points(points_morphed, SIZE, SIZE)\n",
    "\n",
    "    rect = (0, 0, SIZE, SIZE)\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "\n",
    "    for p in points_morphed:\n",
    "        x, y = float(p[0]), float(p[1])\n",
    "        if 0 <= x < SIZE and 0 <= y < SIZE:\n",
    "            try:\n",
    "                subdiv.insert((x, y))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    triangle_list = subdiv.getTriangleList()\n",
    "\n",
    "    tri_indices = []\n",
    "    for t in triangle_list:\n",
    "        tri_pts = [(t[0], t[1]), (t[2], t[3]), (t[4], t[5])]\n",
    "        inds = []\n",
    "        valid = True\n",
    "        for p in tri_pts:\n",
    "            idx = find_point_index(points_morphed, p, tol=5.0)\n",
    "            if idx is None:\n",
    "                valid = False\n",
    "                break\n",
    "            inds.append(idx)\n",
    "        if valid and len(set(inds)) == 3:\n",
    "            tri_indices.append(tuple(inds))\n",
    "\n",
    "    tri_indices = list(set(tri_indices))\n",
    "\n",
    "    img_morphed = np.zeros_like(imgA_color, dtype=np.float32)\n",
    "\n",
    "    for tri in tri_indices:\n",
    "        i1, i2, i3 = tri\n",
    "        tA = [ptsA[i1], ptsA[i2], ptsA[i3]]\n",
    "        tB = [ptsB[i1], ptsB[i2], ptsB[i3]]\n",
    "        tM = [points_morphed[i1], points_morphed[i2], points_morphed[i3]]\n",
    "\n",
    "        if not (triangle_completely_inside(tA, SIZE, SIZE) and \n",
    "                triangle_completely_inside(tB, SIZE, SIZE) and \n",
    "                triangle_completely_inside(tM, SIZE, SIZE)):\n",
    "            continue\n",
    "\n",
    "        morph_triangle(imgA_color, imgB_color, img_morphed, tA, tB, tM, alpha)\n",
    "\n",
    "    morph_result = np.clip(img_morphed, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Verifier que l'image n'est pas noire\n",
    "    if np.mean(morph_result) < 10:\n",
    "        return None\n",
    "    \n",
    "    return morph_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_name(name):\n",
    "    \"\"\"Nettoie le nom pour un nom de fichier valide\"\"\"\n",
    "    # Remplacer les espaces et caracteres speciaux\n",
    "    clean = \"\".join(c if c.isalnum() else '_' for c in str(name))\n",
    "    return clean[:20]  # Limiter a 20 caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_database():\n",
    "    \"\"\"\n",
    "    Genere la base de donnees complete:\n",
    "    - 30 images morphees par paire d'identites\n",
    "    - Format: A_B_N.png (A et B = identites, N = 1 a 30)\n",
    "    \"\"\"\n",
    "    \n",
    "    person_list = list(persons.keys())\n",
    "    all_pairs = list(combinations(person_list, 2))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"GENERATION DE LA BASE DE DONNEES MORPHEE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"   - Paires a traiter: {len(all_pairs)}\")\n",
    "    print(f\"   - Images par paire: {NUM_VARIATIONS}\")\n",
    "    print(f\"   - Total: {len(all_pairs) * NUM_VARIATIONS} images\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Stats\n",
    "    stats = {\n",
    "        \"total_pairs\": len(all_pairs),\n",
    "        \"images_per_pair\": NUM_VARIATIONS,\n",
    "        \"alpha\": ALPHA,\n",
    "        \"size\": SIZE,\n",
    "        \"successful\": 0,\n",
    "        \"failed\": 0,\n",
    "        \"start_time\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Pour afficher des exemples\n",
    "    display_samples = []\n",
    "    \n",
    "    # Generer les morphings\n",
    "    for pair_idx, (nameA, nameB) in enumerate(tqdm(all_pairs, desc=\"Paires\")):\n",
    "        \n",
    "        clean_nameA = sanitize_name(nameA)\n",
    "        clean_nameB = sanitize_name(nameB)\n",
    "        \n",
    "        imgs_a = persons[nameA]\n",
    "        imgs_b = persons[nameB]\n",
    "        \n",
    "        # Generer 30 variations\n",
    "        for n in range(1, NUM_VARIATIONS + 1):\n",
    "            try:\n",
    "                # Selectionner aleatoirement une image de chaque personne\n",
    "                img_a = np.random.choice(imgs_a)\n",
    "                img_b = np.random.choice(imgs_b)\n",
    "                \n",
    "                # Generer le morphing\n",
    "                morph = morph_faces(img_a, img_b, alpha=ALPHA)\n",
    "                \n",
    "                if morph is not None:\n",
    "                    # Nom du fichier: A_B_N.png\n",
    "                    filename = f\"{clean_nameA}_{clean_nameB}_{n}.png\"\n",
    "                    filepath = OUTPUT_DIR / filename\n",
    "                    \n",
    "                    cv2.imwrite(str(filepath), morph)\n",
    "                    stats[\"successful\"] += 1\n",
    "                    \n",
    "                    # Garder quelques exemples pour affichage\n",
    "                    if len(display_samples) < 10 and n == 1:\n",
    "                        imgA = cv2.imread(str(img_a))\n",
    "                        imgB = cv2.imread(str(img_b))\n",
    "                        imgA = cv2.resize(imgA, (SIZE, SIZE))\n",
    "                        imgB = cv2.resize(imgB, (SIZE, SIZE))\n",
    "                        display_samples.append((imgA, morph, imgB, nameA, nameB))\n",
    "                else:\n",
    "                    stats[\"failed\"] += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                stats[\"failed\"] += 1\n",
    "    \n",
    "    # Finaliser les stats\n",
    "    elapsed_time = time.time() - start_time\n",
    "    stats[\"end_time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    stats[\"elapsed_seconds\"] = elapsed_time\n",
    "    stats[\"elapsed_minutes\"] = elapsed_time / 60\n",
    "    \n",
    "    # Sauvegarder les stats\n",
    "    stats_file = OUTPUT_DIR / \"dataset_stats.json\"\n",
    "    with open(stats_file, 'w') as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "    \n",
    "    # Afficher le resume\n",
    "    success_rate = stats[\"successful\"] / max(1, stats[\"successful\"] + stats[\"failed\"]) * 100\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"GENERATION TERMINEE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"   - Paires traitees: {len(all_pairs)}\")\n",
    "    print(f\"   - Images generees: {stats['successful']}\")\n",
    "    print(f\"   - Echecs: {stats['failed']}\")\n",
    "    print(f\"   - Taux de reussite: {success_rate:.1f}%\")\n",
    "    print(f\"   - Temps total: {elapsed_time/60:.1f} minutes\")\n",
    "    print(f\"   - Vitesse: {stats['successful']/max(1,elapsed_time):.1f} images/seconde\")\n",
    "    print(f\"   - Dossier: {OUTPUT_DIR}\")\n",
    "    print(f\"   - Stats: {stats_file}\")\n",
    "    print(f\"\\nFORMAT: A_B_N.png\")\n",
    "    print(f\"   A = Identite 1, B = Identite 2, N = 1 a 30\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return display_samples, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancer la generation\n",
    "samples, stats = generate_full_database()\n",
    "\n",
    "print(f\"\\n[OK] Base de donnees generee!\")\n",
    "print(f\"[OK] {stats['successful']} images dans {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les exemples\n",
    "if samples:\n",
    "    n = len(samples)\n",
    "    fig, axes = plt.subplots(n, 3, figsize=(12, 4*n))\n",
    "    \n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (imgA, morph, imgB, nameA, nameB) in enumerate(samples):\n",
    "        axes[i][0].imshow(cv2.cvtColor(imgA, cv2.COLOR_BGR2RGB))\n",
    "        axes[i][0].set_title(f\"A: {nameA[:15]}\")\n",
    "        axes[i][0].axis('off')\n",
    "        \n",
    "        axes[i][1].imshow(cv2.cvtColor(morph, cv2.COLOR_BGR2RGB))\n",
    "        axes[i][1].set_title(\"MORPH (50%)\")\n",
    "        axes[i][1].axis('off')\n",
    "        \n",
    "        axes[i][2].imshow(cv2.cvtColor(imgB, cv2.COLOR_BGR2RGB))\n",
    "        axes[i][2].set_title(f\"B: {nameB[:15]}\")\n",
    "        axes[i][2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"samples_preview.png\", dpi=150)\n",
    "    plt.show()\n",
    "    print(f\"[OK] Apercu sauvegarde: {OUTPUT_DIR}/samples_preview.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import json\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dossiers\n",
    "MORPHED_DIR = Path(\"./morphed_database\")  # Dossier des images morphees\n",
    "MODEL_DIR = Path(\"./models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Parametres du modele\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"CONFIGURATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"   - Dossier images: {MORPHED_DIR}\")\n",
    "print(f\"   - Taille images: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   - Epochs: {EPOCHS}\")\n",
    "print(f\"   - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_morphed_dataset():\n",
    "    \"\"\"\n",
    "    Charge les images morphees\n",
    "    Format fichier: A_B_N.png -> classe = A_B (identite fictive)\n",
    "    \"\"\"\n",
    "    print(\"\\n[INFO] Chargement des images morphees...\")\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    label_to_idx = {}\n",
    "    idx_to_label = {}\n",
    "    \n",
    "    # Lister tous les fichiers PNG\n",
    "    all_files = list(MORPHED_DIR.glob(\"*.png\"))\n",
    "    print(f\"   {len(all_files)} fichiers trouves\")\n",
    "    \n",
    "    # Grouper par identite fictive (A_B)\n",
    "    identities = defaultdict(list)\n",
    "    \n",
    "    for filepath in all_files:\n",
    "        # Format: A_B_N.png\n",
    "        parts = filepath.stem.rsplit(\"_\", 1)  # Separer le dernier underscore\n",
    "        if len(parts) == 2:\n",
    "            identity = parts[0]  # A_B\n",
    "            identities[identity].append(str(filepath))\n",
    "    \n",
    "    print(f\"   {len(identities)} identites fictives\")\n",
    "    \n",
    "    # Filtrer les identites avec assez d'images\n",
    "    min_images = 10\n",
    "    valid_identities = {k: v for k, v in identities.items() if len(v) >= min_images}\n",
    "    print(f\"   {len(valid_identities)} identites avec {min_images}+ images\")\n",
    "    \n",
    "    # Creer le mapping label -> index\n",
    "    for idx, identity in enumerate(sorted(valid_identities.keys())):\n",
    "        label_to_idx[identity] = idx\n",
    "        idx_to_label[idx] = identity\n",
    "    \n",
    "    # Charger les images\n",
    "    for identity, filepaths in tqdm(valid_identities.items(), desc=\"Chargement\"):\n",
    "        for filepath in filepaths:\n",
    "            img = cv2.imread(filepath)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                images.append(img)\n",
    "                labels.append(label_to_idx[identity])\n",
    "    \n",
    "    images = np.array(images, dtype=np.float32) / 255.0  # Normaliser [0, 1]\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    print(f\"\\n[OK] Dataset charge:\")\n",
    "    print(f\"   - Images: {images.shape}\")\n",
    "    print(f\"   - Classes: {len(label_to_idx)}\")\n",
    "    \n",
    "    return images, labels, label_to_idx, idx_to_label\n",
    "\n",
    "# Charger les donnees\n",
    "X, y, label_to_idx, idx_to_label = load_morphed_dataset()\n",
    "NUM_CLASSES = len(label_to_idx)\n",
    "print(f\"   - Nombre de classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split: 70% train, 15% val, 15% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Convertir labels en one-hot\n",
    "y_train_cat = to_categorical(y_train, NUM_CLASSES)\n",
    "y_val_cat = to_categorical(y_val, NUM_CLASSES)\n",
    "y_test_cat = to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "print(f\"\\n[OK] Split des donnees:\")\n",
    "print(f\"   - Train: {X_train.shape[0]} images\")\n",
    "print(f\"   - Validation: {X_val.shape[0]} images\")\n",
    "print(f\"   - Test: {X_test.shape[0]} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenet_model(num_classes, img_size=128):\n",
    "    \"\"\"\n",
    "    Cree un modele MobileNetV2 pour la classification\n",
    "    \"\"\"\n",
    "    # Charger MobileNetV2 pre-entraine (sans la tete)\n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(img_size, img_size, 3)\n",
    "    )\n",
    "    \n",
    "    # Geler les couches de base (transfer learning)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Ajouter notre tete de classification\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Creer le modele\n",
    "model, base_model = create_mobilenet_model(NUM_CLASSES, IMG_SIZE)\n",
    "\n",
    "# Compiler\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "print(f\"\\n[OK] Modele MobileNetV2 cree avec {NUM_CLASSES} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation pour l'entrainement\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()  # Pas d'augmentation pour validation\n",
    "\n",
    "# Creer les generateurs\n",
    "train_generator = train_datagen.flow(X_train, y_train_cat, batch_size=BATCH_SIZE)\n",
    "val_generator = val_datagen.flow(X_val, y_val_cat, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"[OK] Data augmentation configuree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=str(MODEL_DIR / 'mobilenet_morphed_best.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"[OK] Callbacks configures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PHASE 1: TRANSFER LEARNING (couches gelees)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "history1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(X_val) // BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n[OK] Phase 1 terminee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PHASE 2: FINE-TUNING (couches degelees)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Degeler les dernieres couches du modele de base\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompiler avec un learning rate plus faible\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE / 10),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(X_val) // BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n[OK] Phase 2 terminee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modele final\n",
    "model.save(MODEL_DIR / 'mobilenet_morphed_final.keras')\n",
    "\n",
    "# Sauvegarder les mappings\n",
    "mappings = {\n",
    "    'label_to_idx': label_to_idx,\n",
    "    'idx_to_label': idx_to_label\n",
    "}\n",
    "with open(MODEL_DIR / 'label_mappings.json', 'w') as f:\n",
    "    json.dump(mappings, f, indent=2)\n",
    "\n",
    "print(f\"[OK] Modele sauvegarde: {MODEL_DIR / 'mobilenet_morphed_final.keras'}\")\n",
    "print(f\"[OK] Mappings sauvegardes: {MODEL_DIR / 'label_mappings.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "SIZE = 128\n",
    "ALPHA = 0.5\n",
    "NUM_VARIATIONS = 100  # Augmenté de 30 à 100\n",
    "MIN_IMAGES_PER_PERSON = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_morphed_dataset():\n",
    "    print(\"\\n[INFO] Chargement des images morphees...\")\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    label_to_idx = {}\n",
    "    idx_to_label = {}\n",
    "    \n",
    "    all_files = list(MORPHED_DIR.glob(\"*.png\"))\n",
    "    print(f\"   {len(all_files)} fichiers trouves\")\n",
    "    \n",
    "    identities = defaultdict(list)\n",
    "    \n",
    "    for filepath in all_files:\n",
    "        parts = filepath.stem.rsplit(\"_\", 1)\n",
    "        if len(parts) == 2:\n",
    "            identity = parts[0]\n",
    "            identities[identity].append(str(filepath))\n",
    "    \n",
    "    print(f\"   {len(identities)} identites fictives\")\n",
    "    \n",
    "    # AUGMENTER le minimum d'images par classe\n",
    "    min_images = 50  # Augmenté de 10 à 50\n",
    "    valid_identities = {k: v for k, v in identities.items() if len(v) >= min_images}\n",
    "    \n",
    "    # LIMITER le nombre de classes\n",
    "    MAX_CLASSES = 20  # Limiter à 20 classes\n",
    "    valid_identities = dict(list(sorted(valid_identities.items(), \n",
    "                                         key=lambda x: len(x[1]), \n",
    "                                         reverse=True))[:MAX_CLASSES])\n",
    "    \n",
    "    print(f\"   {len(valid_identities)} identites selectionnees (top {MAX_CLASSES})\")\n",
    "    \n",
    "    for idx, identity in enumerate(sorted(valid_identities.keys())):\n",
    "        label_to_idx[identity] = idx\n",
    "        idx_to_label[idx] = identity\n",
    "    \n",
    "    for identity, filepaths in tqdm(valid_identities.items(), desc=\"Chargement\"):\n",
    "        for filepath in filepaths:\n",
    "            img = cv2.imread(filepath)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                images.append(img)\n",
    "                labels.append(label_to_idx[identity])\n",
    "    \n",
    "    images = np.array(images, dtype=np.float32) / 255.0\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    print(f\"\\n[OK] Dataset charge:\")\n",
    "    print(f\"   - Images: {images.shape}\")\n",
    "    print(f\"   - Classes: {len(label_to_idx)}\")\n",
    "    print(f\"   - Images/classe: ~{len(images)//len(label_to_idx)}\")\n",
    "    \n",
    "    return images, labels, label_to_idx, idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.3,\n",
    "    brightness_range=[0.6, 1.4],\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les historiques\n",
    "def combine_histories(h1, h2):\n",
    "    combined = {}\n",
    "    for key in h1.history.keys():\n",
    "        combined[key] = h1.history[key] + h2.history[key]\n",
    "    return combined\n",
    "\n",
    "history = combine_histories(history1, history2)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history['accuracy'], label='Train')\n",
    "axes[0].plot(history['val_accuracy'], label='Validation')\n",
    "axes[0].set_title('Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history['loss'], label='Train')\n",
    "axes[1].plot(history['val_loss'], label='Validation')\n",
    "axes[1].set_title('Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_DIR / 'training_history.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"[OK] Historique sauvegarde: {MODEL_DIR / 'training_history.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "    epochs=50,  # Augmenté de 20 à 50\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(X_val) // BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PREPARATION POUR MEMBERSHIP INFERENCE ATTACK (MIA)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Pour MIA, on a besoin de:\n",
    "# 1. Membres (train set) - le modele les a vus\n",
    "# 2. Non-membres (test set) - le modele ne les a pas vus\n",
    "\n",
    "# Obtenir les predictions de confiance\n",
    "train_predictions = model.predict(X_train, verbose=0)\n",
    "test_predictions = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Calculer les scores de confiance (max probability)\n",
    "train_confidence = np.max(train_predictions, axis=1)\n",
    "test_confidence = np.max(test_predictions, axis=1)\n",
    "\n",
    "# Calculer si la prediction est correcte\n",
    "train_correct = (np.argmax(train_predictions, axis=1) == y_train).astype(int)\n",
    "test_correct = (np.argmax(test_predictions, axis=1) == y_test).astype(int)\n",
    "\n",
    "print(f\"[INFO] Statistiques de confiance:\")\n",
    "print(f\"   Train - Confiance moyenne: {train_confidence.mean():.4f}\")\n",
    "print(f\"   Test  - Confiance moyenne: {test_confidence.mean():.4f}\")\n",
    "print(f\"   Train - Accuracy: {train_correct.mean()*100:.2f}%\")\n",
    "print(f\"   Test  - Accuracy: {test_correct.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer les features pour l'attaque MIA\n",
    "def create_mia_features(predictions, labels, correct):\n",
    "    \"\"\"\n",
    "    Cree les features pour l'attaque MIA:\n",
    "    - Confiance max\n",
    "    - Entropie\n",
    "    - Confiance sur la vraie classe\n",
    "    - Prediction correcte ou non\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        pred = predictions[i]\n",
    "        true_label = labels[i]\n",
    "        \n",
    "        # Confiance max\n",
    "        max_conf = np.max(pred)\n",
    "        \n",
    "        # Entropie\n",
    "        entropy = -np.sum(pred * np.log(pred + 1e-10))\n",
    "        \n",
    "        # Confiance sur la vraie classe\n",
    "        true_conf = pred[true_label]\n",
    "        \n",
    "        # Difference entre top 1 et top 2\n",
    "        sorted_pred = np.sort(pred)[::-1]\n",
    "        margin = sorted_pred[0] - sorted_pred[1]\n",
    "        \n",
    "        features.append([max_conf, entropy, true_conf, margin, correct[i]])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Creer les features\n",
    "train_mia_features = create_mia_features(train_predictions, y_train, train_correct)\n",
    "test_mia_features = create_mia_features(test_predictions, y_test, test_correct)\n",
    "\n",
    "# Labels MIA: 1 = membre (train), 0 = non-membre (test)\n",
    "train_mia_labels = np.ones(len(train_mia_features))\n",
    "test_mia_labels = np.zeros(len(test_mia_features))\n",
    "\n",
    "# Combiner\n",
    "X_mia = np.vstack([train_mia_features, test_mia_features])\n",
    "y_mia = np.concatenate([train_mia_labels, test_mia_labels])\n",
    "\n",
    "print(f\"[OK] Dataset MIA cree:\")\n",
    "print(f\"   - Total samples: {len(X_mia)}\")\n",
    "print(f\"   - Membres (train): {int(train_mia_labels.sum())}\")\n",
    "print(f\"   - Non-membres (test): {int(len(test_mia_labels) - test_mia_labels.sum())}\")\n",
    "print(f\"   - Features: {X_mia.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Split MIA dataset\n",
    "X_mia_train, X_mia_test, y_mia_train, y_mia_test = train_test_split(\n",
    "    X_mia, y_mia, test_size=0.3, random_state=42, stratify=y_mia\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ENTRAINEMENT DU MODELE D'ATTAQUE MIA\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Modele 1: Random Forest\n",
    "rf_attack = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_attack.fit(X_mia_train, y_mia_train)\n",
    "rf_pred = rf_attack.predict(X_mia_test)\n",
    "rf_proba = rf_attack.predict_proba(X_mia_test)[:, 1]\n",
    "\n",
    "rf_accuracy = accuracy_score(y_mia_test, rf_pred)\n",
    "rf_auc = roc_auc_score(y_mia_test, rf_proba)\n",
    "\n",
    "print(f\"[Random Forest]\")\n",
    "print(f\"   - Accuracy: {rf_accuracy*100:.2f}%\")\n",
    "print(f\"   - AUC: {rf_auc:.4f}\")\n",
    "\n",
    "# Modele 2: Logistic Regression\n",
    "lr_attack = LogisticRegression(random_state=42)\n",
    "lr_attack.fit(X_mia_train, y_mia_train)\n",
    "lr_pred = lr_attack.predict(X_mia_test)\n",
    "lr_proba = lr_attack.predict_proba(X_mia_test)[:, 1]\n",
    "\n",
    "lr_accuracy = accuracy_score(y_mia_test, lr_pred)\n",
    "lr_auc = roc_auc_score(y_mia_test, lr_proba)\n",
    "\n",
    "print(f\"\\n[Logistic Regression]\")\n",
    "print(f\"   - Accuracy: {lr_accuracy*100:.2f}%\")\n",
    "print(f\"   - AUC: {lr_auc:.4f}\")\n",
    "\n",
    "# Baseline: attaque par seuil de confiance\n",
    "threshold = 0.5\n",
    "threshold_pred = (X_mia_test[:, 0] > threshold).astype(int)  # Confiance max\n",
    "threshold_accuracy = accuracy_score(y_mia_test, threshold_pred)\n",
    "\n",
    "print(f\"\\n[Baseline - Seuil de confiance]\")\n",
    "print(f\"   - Accuracy: {threshold_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# 1. Distribution des confiances\n",
    "axes[0].hist(train_confidence, bins=50, alpha=0.7, label='Membres (Train)', color='blue')\n",
    "axes[0].hist(test_confidence, bins=50, alpha=0.7, label='Non-membres (Test)', color='red')\n",
    "axes[0].set_xlabel('Confiance')\n",
    "axes[0].set_ylabel('Frequence')\n",
    "axes[0].set_title('Distribution des Confiances')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 2. Courbe ROC\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_mia_test, rf_proba)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_mia_test, lr_proba)\n",
    "\n",
    "axes[1].plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC={rf_auc:.3f})', color='blue')\n",
    "axes[1].plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC={lr_auc:.3f})', color='green')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.5)')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('Courbe ROC - MIA')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# 3. Importance des features (Random Forest)\n",
    "feature_names = ['Max Conf', 'Entropy', 'True Conf', 'Margin', 'Correct']\n",
    "importances = rf_attack.feature_importances_\n",
    "axes[2].barh(feature_names, importances, color='steelblue')\n",
    "axes[2].set_xlabel('Importance')\n",
    "axes[2].set_title('Importance des Features (RF)')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_DIR / 'mia_results.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n[OK] Resultats MIA sauvegardes: {MODEL_DIR / 'mia_results.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESUME - MEMBERSHIP INFERENCE ATTACK\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\"\"\n",
    "OBJECTIF:\n",
    "   Determiner si le modele a memorise les visages sources\n",
    "   utilises pour creer les identites fictives (morphees).\n",
    "\n",
    "RESULTATS:\n",
    "   - Modele cible (MobileNetV2):\n",
    "     * Train Accuracy: {train_correct.mean()*100:.2f}%\n",
    "     * Test Accuracy: {test_correct.mean()*100:.2f}%\n",
    "   \n",
    "   - Attaque MIA (Random Forest):\n",
    "     * Accuracy: {rf_accuracy*100:.2f}%\n",
    "     * AUC: {rf_auc:.4f}\n",
    "   \n",
    "   - Attaque MIA (Logistic Regression):\n",
    "     * Accuracy: {lr_accuracy*100:.2f}%\n",
    "     * AUC: {lr_auc:.4f}\n",
    "\n",
    "INTERPRETATION:\n",
    "   - AUC = 0.5: Pas de fuite d'information (modele securise)\n",
    "   - AUC > 0.5: Fuite d'information detectee\n",
    "   - AUC > 0.7: Fuite significative (modele vulnerable)\n",
    "   - AUC > 0.9: Fuite severe (modele tres vulnerable)\n",
    "\n",
    "   Votre modele: AUC = {rf_auc:.4f}\n",
    "\"\"\")\n",
    "\n",
    "if rf_auc > 0.7:\n",
    "    print(\"   [ALERTE] Le modele presente une vulnerabilite MIA significative!\")\n",
    "    print(\"   Les informations sur les visages sources peuvent etre inferees.\")\n",
    "elif rf_auc > 0.55:\n",
    "    print(\"   [ATTENTION] Le modele presente une legere vulnerabilite MIA.\")\n",
    "else:\n",
    "    print(\"   [OK] Le modele semble resistant a l'attaque MIA.\")\n",
    "\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
