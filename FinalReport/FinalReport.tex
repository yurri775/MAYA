\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}

\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{float}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}

\geometry{margin=2.5cm}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    language=Python
}
\lstset{style=mystyle}

\title{
    \vspace{-2cm}
    \textbf{Rapport Technique Global / PART 2}\\[0.2cm]
    \Large{Morphing de Visages, Classification sur Identit\'es Fictives\\
    et Attaque de Type Membership Inference (MIA)}
}
\author{
    Projet de Recherche\\
    \small{Morphing, Reconnaissance Faciale et Vie Priv\'ee}
}
%\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Ce rapport pr\'esente l'ensemble du travail r\'ealis\'e au cours du projet, depuis
les premiers prototypes de morphing facial jusqu'\`a l'entra\^\i{}nement d'un r\'eseau
de neurones convolutif (MobileNetV2) et \`a la mise en \oe uvre d'une attaque
de type Membership Inference Attack (MIA). Nous d\'ecrivons d'abord le pipeline
de morphing g\'eom\'etrique (landmarks faciaux, triangulation de Delaunay,
transformations affines et alpha-blending), test\'e initialement sur un petit
jeu de visages puis appliqu\'e \`a un jeu de visages de meilleure qualit\'e pour
g\'en\'erer un grand dataset fictif (\texttt{big\_dataset\_alpha}). Dans une
seconde phase, nous repartons d'identit\'es r\'eelles issues de LFW et construisons
un dataset synth\'etique \texttt{big\_dataset\_lfw} \`a partir d'images morph\'ees.
Un MobileNetV2 pr\'e-entra\^\i{}n\'e sur ImageNet est ensuite adapt\'e \`a la t\^ache de
reconnaissance d'identit\'es fictives. 
%Enfin, nous pr\'eparons et analysons une
%attaque MIA visant \`a distinguer les images ayant servi \`a l'entra\^\i{}nement de
%celles utilis\'ees uniquement en test. Le rapport insiste \'egalement sur les
%difficult\'es rencontr\'ees (\'ech\'ecs de d\'etection de landmarks, poses extr\^emes,
%probl\'emes de split pour MIA) et les solutions mises en place.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Introduction G\'en\'erale}
%==============================================================================

Les syst\`emes de morphing facial permettent de g\'en\'erer des visages
\og interm\'ediaires \fg{} \`a partir de deux donneurs $A$ et $B$. D'un point de
vue applicatif, ces techniques sont \'etudi\'ees \`a la fois pour des usages
cr\'eatifs (animation, cin\'ema) et pour leurs implications en s\'ecurit\'e
biom\'etrique, notamment les attaques par morphing sur les syst\`emes de
v\'erification de passeports.

Parall\`element, l'entra\^\i{}nement de mod\`eles de reconnaissance faciale soul\`eve
des questions fortes de confidentialit\'e : un attaquant peut-il d\'eterminer
si une image pr\'ecise a fait partie de la base d'entra\^\i{}nement d'un mod\`ele
donn\'e~? C'est pr\'ecis\'ement l'objectif des Membership Inference Attacks (MIA).

Notre projet s'articule autour de ces deux axes~:
\begin{itemize}
  \item construire des pipelines de morphing g\'eom\'etrique contr\^ol\'e,
        puis g\'en\'erer de grands jeux de donn\'ees de visages fictifs
        (identit\'es synth\'etiques) ;
  \item entra\^\i{}ner un r\'eseau MobileNetV2 sur ces identit\'es fictives et
        \'etudier la vuln\'erabilit\'e du mod\`ele face \`a une attaque MIA.
\end{itemize}

Nous avons progressivement \'evolu\'e :
\begin{enumerate}
  \item d'un prototype simple de morphing (sur un petit jeu de visages
        align\'es) vers un pipeline plus robuste sur des visages de
        meilleure qualit\'e ;
  \item d'un dataset interne \texttt{big\_dataset\_alpha} vers un dataset
        synth\'etique d\'eriv\'e de LFW, \texttt{big\_dataset\_lfw} ;
  \item d'une simple g\'en\'eration d'images morph\'ees vers un sc\'enario complet
        \og classification + attaque MIA \fg.
\end{enumerate}

%==============================================================================
\section{Morphing G\'eom\'etrique de Visages}
%==============================================================================

\subsection{Prototype initial sur un petit jeu de visages}

Avant d'industrialiser le pipeline, nous avons mis en place un prototype
sur un petit jeu de visages align\'es. L'objectif \'etait de valider les
briques de base :
\begin{itemize}
  \item d\'etection de points de rep\`ere (landmarks) sur des visages
        centr\'es et sans forte variation de pose ;
  \item triangulation de Delaunay sur ces points pour obtenir une
        d\'ecomposition robuste du visage en triangles ;
  \item warping affine triangle par triangle et m\'elange (alpha-blending)
        entre les deux visages.
\end{itemize}

Ce prototype nous a permis de v\'erifier rapidement que, sur des visages bien
align\'es et de petite taille, le morphing g\'eom\'etrique classique produit des
r\'esultats satisfaisants. Les difficult\'es principales apparaissent d\`es que
l'on augmente la variabilit\'e du dataset (poses, expressions, \'eclairage, \dots),
ce qui a motiv\'e la suite du travail.

\subsection{Pipeline g\'en\'eral de morphing}

Dans la suite du projet (dossier \texttt{simple\_morph}), nous avons adopt\'e
une architecture g\'en\'erique inspir\'ee des travaux classiques sur les
68 landmarks dlib et la triangulation de Delaunay.

Pour deux images sources $I_A$ et $I_B$, le pipeline est le suivant~:
\begin{enumerate}
  \item redimensionner $I_A$ et $I_B$ \`a une taille fixe $(H, W)$ pour
        avoir une g\'eom\'etrie commune ;
  \item d\'etecter les 68 landmarks sur chaque visage avec
        \texttt{shape\_predictor\_68\_face\_landmarks.dat} ;
  \item ajouter des points de bord (coins de l'image et milieux
        des bords) afin de stabiliser la triangulation jusque dans le fond ;
  \item calculer l'ensemble moyen de points $L_{\text{avg}} = (L_A + L_B)/2$
        et construire la triangulation de Delaunay sur ces points ;
  \item pour un coefficient $\alpha \in [0,1]$, interpoler les points
        \[
           L_\alpha = (1-\alpha)\,L_A + \alpha\,L_B ;
        \]
  \item pour chaque triangle de la triangulation, calculer une
        transformation affine qui envoie le triangle de $A$ (resp.
        de $B$) vers sa position correspondante dans $L_\alpha$, puis
        warper localement les pixels ;
  \item combiner les deux images warp\'ees par alpha-blending, en limitant
        le m\'elange \`a l'int\'erieur d'un masque de visage doux afin d'\'eviter
        de m\'elanger les fonds et les cheveux.
\end{enumerate}

En notation compacte, si l'on note $I_A'$ et $I_B'$ les images warp\'ees
dans la g\'eom\'etrie interm\'ediaire, l'image morph\'ee $I_M$ s'\'ecrit
\[
I_M = (1-\alpha)\,I_A' + \alpha\,I_B'.
\]

\subsection{Masque de visage et fusion contr\^ol\'ee}

Un probl\`eme r\'ecurrent dans le morphing na\:if est le m\'elange du fond et des
cheveux, qui g\'en\`ere des artefacts tr\`es visibles. Pour limiter cela, nous
construisons un \emph{masque de visage} \`a partir des seuls points anatomiques
(68 landmarks) sans les points de bord~:
\begin{itemize}
  \item calcul de l'enveloppe convexe des 68 points ;
  \item remplissage de ce polygone (masque binaire) ;
  \item l\'eg\`ere \"r\'eduction\" (\'erosion) + flou gaussien pour obtenir un masque
        \og doux \fg.
\end{itemize}

L'image finale est alors :
\[
\text{composite} = \text{morph} \times \text{masque} +
                   \text{fond\_B} \times (1 - \text{masque}),
\]
o√π \texttt{fond\_B} est simplement l'image $B$ redimensionn\'ee.

\subsection{G\'en\'eration d'identit\'es multiples et dataset
            \texttt{big\_dataset\_alpha}}

\`A partir de ce pipeline, nous avons construit un premier grand jeu
de donn\'ees fictif \texttt{big\_dataset\_alpha}. L'id\'ee est la suivante~:
\begin{itemize}
  \item disposer de dossiers \texttt{images/enfant},
        \texttt{images/Homme}, \texttt{images/Femme} contenant des
        visages relativement homog\`enes ;
  \item ne g\'en\'erer que des morphs \emph{intra--groupe}
        (enfant--enfant, homme--homme, femme--femme) pour \'eviter les
        d\'eformations extr\^emes (adulte + enfant, etc.) ;
  \item pour chaque paire $(A,B)$ compatible, g\'en\'erer plusieurs morphs
        en faisant varier $\alpha \in \{0.4, 0.5, 0.7\}$, ce qui cr\'ee
        plusieurs identit\'es synth\'etiques distinctes \`a partir des m\^emes
        donneurs.
\end{itemize}

Les morphs de base sont stock\'es dans un dossier
\texttt{morph\_identities\_alpha} avec des noms codant les donneurs et
la valeur de $\alpha$.

Pour disposer de suffisamment d'exemples par identit\'e, nous appliquons
ensuite un script d'augmentation \texttt{augment\_identities.py} qui
cr\'e\'e, pour chaque morph de base, une copie originale + $N$ augmentations
l\'eg\`eres (rotation $\pm 5^\circ$, petites translations, jitter de
contraste/luminosit\'e, bruit gaussien, l\'eger flou ponctuel). Avec
plusieurs centaines de morphs de base et $N = 30$ augmentations, nous
obtenons plus de 23\,000 images fictives dans
\texttt{big\_dataset\_alpha}.

\subsection{Difficult\'es rencontr\'ees sur le morphing}

Les principales difficult\'es ont \'et\'e~:
\begin{itemize}
  \item \textbf{\'Echecs de d\'etection de landmarks} : certaines images
        (poses tr\`es de profil, occlusions, lumi\`ere tr\`es faible)
        provoquaient un \'echec ou une mauvaise localisation des points.
        Nous avons limit\'e l'impact en filtrant les paires trop
        probl\'ematiques et en ajoutant un fallback (grille r\'eguli\`ere)
        quand la d\'etection \'echoue.
  \item \textbf{M\'elange adulte/enfant et poses incompatibles}~:
        les premiers essais m\'elangeant des visages tr\`es diff\'erents
        donnaient des morphs irr\'ealistes (yeux d\'edoubl\'es, cr\^ane
        d\'eform\'e). La solution a \'et\'e de s\'eparer les jeux d'images par
        groupes homog\`enes (enfant / homme / femme) et d'imposer des
        morphs uniquement intra--groupe.
  \item \textbf{Artefacts aux fronti\`eres du visage}~:
        m\^eme avec la triangulation, des discontinuit\'es restaient
        visibles au niveau des contours du visage et des cheveux.
        Nous les avons r\'eduits gr\^ace au masque flout\'e et \`a un
        l\'eger \emph{sharpening} final.
\end{itemize}

%==============================================================================
\section{Base Synth\'etique LFW et Triptyques A $\mid$ C $\mid$ B}
%==============================================================================

\subsection{S\'election d'identit\'es dans LFW}

Dans une seconde phase, nous avons voulu reconstruire un pipeline
similaire \`a partir de la base publique Labeled Faces in the Wild (LFW).
L'objectif est de disposer d'identit\'es bien identifi\'ees, avec de
nombreuses photos par personne, pour construire des identit\'es
\emph{fictives} par morphing.

Nous proc\'edons ainsi :
\begin{enumerate}
  \item t\'el\'echargement de LFW via \texttt{fetch\_lfw\_people}
        (\texttt{scikit-learn}) ;
  \item filtrage pour ne garder que les identit\'es avec au moins
        30 images ;
  \item s\'election de 10 identit\'es parmi les plus fr\'equentes ;
  \item export des images correspondantes dans
        \texttt{images/lfw\_person\_01}, \dots,
        \texttt{images/lfw\_person\_10}.
\end{enumerate}

Nous formons ensuite 5 paires d'identit\'es r\'eelles :
\[
(01,02),\ (03,04),\ (05,06),\ (07,08),\ (09,10).
\]

Pour chaque paire $(A,B)$, nous construisons 50 couples d'images
$(A_i,B_i)$ en parcourant les fichiers tri\'es par nom, puis nous
appliquons le pipeline de morphing g\'eom\'etrique avec $\alpha = 0{,}5$
pour obtenir une identit\'e interm\'ediaire $C_i$.

\subsection{Triptyques visuels A $\mid$ C $\mid$ B}

Afin de documenter clairement les morphs utilis\'es, nous g\'en\'erons
pour chaque couple $(A_i,B_i)$ un panneau horizontal montrant le
triptyque $(A_i, C_i, B_i)$. Le script
\texttt{create\_lfw\_triptychs.py} enregistre ces panneaux dans
\texttt{..\lfw\_morph\_comparison/}.



Ces figures servent de \og preuve visuelle \fg{} de la qualit\'e des morphs
fournis et de base \`a la construction du dataset synth\'etique
\texttt{big\_dataset\_lfw}.

%==============================================================================
\section{Dataset \texttt{big\_dataset\_lfw} et T\^ache de Classification}
%==============================================================================

\subsection{Construction du dataset synth\'etique}

\`A partir des 250 morphs de base (5 paires d'identit\'es r\'eelles
$\times 50$ couples d'images), nous construisons un dataset
\emph{purement fictif} destin\'e \`a la reconnaissance faciale :
chaque morph de base d\'efinit une identit\'e synth\'etique distincte.

Comme pour \texttt{big\_dataset\_alpha}, nous appliquons une
augmentation de donn\'ees contr\^ol\'ee :
\begin{itemize}
  \item pour chaque morph de base $C_i$, nous gardons l'image
        originale ;
  \item nous g\'en\'erons $n_{\text{aug}} = 7$ augmentations l\'eg\`eres
        (rotation, translation, jitter de luminosit\'e/contraste,
        bruit, flou) ;
  \item au total, chaque identit\'e synth\'etique dispose donc de
        $1 + 7 = 8$ images.
\end{itemize}

Le dataset complet \texttt{big\_dataset\_lfw} contient ainsi
\[
250\ \text{identit\'es} \times 8\ \text{images}
= 2000\ \text{images fictives}.
\]

Les identit\'es sont inf\'er\'ees \`a partir du pr\'efixe du nom de fichier
(avant les suffixes \\texttt{\\_orig} / \\texttt{\\_augXXX}).

Pour rendre plus concret le lien entre les donneurs r\'eels $A$, $B$ et
les identit\'es synth\'etiques $C$, la figure~\ref{fig:lfw-donors-morphs}
montre, pour quelques paires d'identit\'es LFW s\'electionn\'ees,
une image source de chaque donneur et un morph $C$ correspondant
issu directement de \texttt{big\_dataset\_lfw}.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{C:/Users/papaa/Desktop/FACEMOMO/lfw_morph_comparison/image.png}
  \caption{Image de comparaison des morphs LFW}
  \label{fig:image-morph}
\end{figure}


\begin{figure}[H]
  \centering
  % Paire (01,02)
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../images/lfw_person_01/img_001.png}
    \caption*{Donneur A (01, img\_001)}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../big_dataset_lfw/morph_lfw_01_02__img_001__img_001__a050_pair01_aug001.png}
    \caption*{Morph C (01,02, img\_001)}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../images/lfw_person_02/img_001.png}
    \caption*{Donneur B (02, img\_001)}
  \end{subfigure}\\[0.3cm]

  % Paire (03,04)
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../images/lfw_person_03/img_001.png}
    \caption*{Donneur A (03, img\_001)}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../big_dataset_lfw/morph_lfw_03_04__img_001__img_001__a050_pair01_aug001.png}
    \caption*{Morph C (03,04, img\_001)}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../images/lfw_person_04/img_001.png}
    \caption*{Donneur B (04, img\_001)}
  \end{subfigure}\\[0.3cm]

  % Paire (05,06)
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../images/lfw_person_05/img_001.png}
    \caption*{Donneur A (05, img\_001)}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../big_dataset_lfw/morph_lfw_05_06__img_001__img_001__a050_pair01_aug001.png}
    \caption*{Morph C (05,06, img\_001)}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../images/lfw_person_06/img_001.png}
    \caption*{Donneur B (06, img\_001)}
  \end{subfigure}

  \caption{Exemples de triptyques $A \mid C \mid B$ construits
           \`a partir des images LFW originales (donneurs) et des
           morphs interm\'ediaires $C$ effectivement utilis\'es dans
           le dataset \texttt{big\_dataset\_lfw}.}
  \label{fig:lfw-donors-morphs}
\end{figure}


\subsection{T\^ache de classification}

La t\^ache principale est une classification multi-classes : \`a partir
 d'une image synth\'etique $x$, le mod\`ele doit pr\'edire l'identit\'e
$y \in \{1, \dots, 250\}$. Nous utilisons un MobileNetV2 pr\'e-entra\^\i{}n\'e
sur ImageNet, dont la derni\`ere couche enti\`erement connect\'ee est
remplac\'ee par une couche lin\'eaire de dimension 250.

Le pr\'etraitement des images suit les pratiques courantes :
\begin{itemize}
  \item redimensionnement en $256\times 256$ puis recadrage al\'eatoire
        en $224\times 224$ pour l'entra\^\i{}nement
        (\emph{RandomResizedCrop}) ;
  \item \textit{horizontal flip} al\'eatoire ;
  \item normalisation par les moyennes / \'ecarts-types d'ImageNet.
\end{itemize}

Nous utilisons l'optimiseur Adam (taux d'apprentissage $10^{-3}$,
\emph{weight decay} $10^{-4}$) et une entropie crois\'ee multi-classe.

\subsection{Split 80\,\% / 20\,\% par identit\'e}

Pour r\'epondre \`a la consigne \og 80\,\% des images pour l'entra\^\i{}nement
et 20\,\% pour le test, par identit\'e \fg{}, le split est effectu\'e
\emph{par classe} :
\begin{itemize}
  \item pour chaque identit\'e $k$, nous m\'elangeons al\'eatoirement les 8
        indices d'images disponibles ;
  \item environ 80\,\% (6 ou 7 images) sont allou\'ees \`a l'ensemble
        d'entra\^\i{}nement ;
  \item les 20\,\% restantes (1 ou 2 images) sont allou\'ees \`a
        l'ensemble de validation / test.
\end{itemize}

Sur l'ensemble du dataset~:
\[
\text{train} \approx 1500\ \text{images}, \quad
\text{val}   \approx  500\ \text{images},
\]
r\'eparties sur 250 identit\'es.

\subsection{R\'esultats de classification}

Malgr\'e une architecture relativement l\'eg\`ere (MobileNetV2) et un
entra\^\i{}nement sur CPU, la t\^ache est \og facile \fg{} pour le r\'eseau car
les identit\'es sont bien s\'epar\'ees et chaque identit\'e dispose de
plusieurs images augment\'ees.

Un entra\^\i{}nement typique sur 5 \''epoques donne :
\begin{itemize}
  \item \textbf{\'Epoque 1} : $\text{train\_acc} \approx 10{,}1\,\%$,
        $\text{val\_acc} \approx 49{,}4\,\%$ ;
  \item \textbf{\'Epoque 2} : $\text{train\_acc} \approx 76{,}7\,\%$,
        $\text{val\_acc} \approx 98{,}4\,\%$ ;
  \item \textbf{\'Epoque 3} : $\text{train\_acc} \approx 99{,}6\,\%$,
        $\text{val\_acc} = 100{,}0\,\%$ ;
  \item \textbf{\'Epoques 4--5} : $\text{train\_acc} \approx 100\,\%$,
        $\text{val\_acc} = 100\,\%$.
\end{itemize}

Le meilleur mod\`ele (en termes de pr\'ecision sur la validation) est
sauvegard\'e dans le fichier
\texttt{mobilenet\_big\_dataset\_alpha.pth}.

\subsection{Difficult\'es rencontr\'ees pour la classification}

Les principales difficult\'es n'ont pas \'et\'e d'atteindre une bonne
performance, mais de garantir un split compatible avec la suite MIA~:
\begin{itemize}
  \item il a fallu s'assurer que le split 80/20 \'etait bien r\'ealis\'e
        \emph{par classe} pour \'eviter que certaines identit\'es soient
        uniquement en train ou uniquement en test ;
  \item il a \'egalement fallu enregistrer explicitement les indices
        des images utilis\'ees pour l'entra\^\i{}nement et celles
        r\'eserv\'ees \`a la validation, sous la forme du fichier
        \texttt{membership\_split\_big\_dataset\_lfw.npz}, afin de
        pouvoir les r\'eutiliser pour l'attaque MIA.
\end{itemize}

%==============================================================================
\section{Pr\'eparation et R\'esultats de l'Attaque MIA}
%==============================================================================
%

\end{document}
