\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{float}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}

\geometry{margin=2.5cm}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    language=Python
}
\lstset{style=mystyle}

\title{
    \vspace{-2cm}
    \textbf{Rapport Technique Global}\\[0.2cm]
    \Large{Morphing de Visages, Classification sur Identit\'es Fictives\\
    et Attaque de Type Membership Inference (MIA)}
}
\author{
    Projet de Recherche en Vision par Ordinateur\\
    \small{Morphing, Reconnaissance Faciale et Vie Priv\'ee}
}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Ce rapport pr\'esente l'ensemble du travail r\'ealis\'e au cours du projet, depuis
les premiers prototypes de morphing facial jusqu'\`a l'entra\^\i{}nement d'un r\'eseau
de neurones convolutif (MobileNetV2) et \`a la mise en \oe uvre d'une attaque
de type Membership Inference Attack (MIA). Nous d\'ecrivons d'abord le pipeline
de morphing g\'eom\'etrique (landmarks faciaux, triangulation de Delaunay,
transformations affines et alpha-blending), test\'e initialement sur un petit
jeu de visages puis appliqu\'e \`a un jeu de visages de meilleure qualit\'e pour
g\'en\'erer un grand dataset fictif (\texttt{big\_dataset\_alpha}). Dans une
seconde phase, nous repartons d'identit\'es r\'eelles issues de LFW et construisons
un dataset synth\'etique \texttt{big\_dataset\_lfw} \`a partir d'images morph\'ees.
Un MobileNetV2 pr\'e-entra\^\i{}n\'e sur ImageNet est ensuite adapt\'e \`a la t\^ache de
reconnaissance d'identit\'es fictives. Enfin, nous pr\'eparons et analysons une
attaque MIA visant \`a distinguer les images ayant servi \`a l'entra\^\i{}nement de
celles utilis\'ees uniquement en test. Le rapport insiste \'egalement sur les
difficult\'es rencontr\'ees (\'ech\'ecs de d\'etection de landmarks, poses extr\^emes,
probl\'emes de split pour MIA) et les solutions mises en place.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Introduction G\'en\'erale}
%==============================================================================

Les syst\`emes de morphing facial permettent de g\'en\'erer des visages
\og interm\'ediaires \fg{} \`a partir de deux donneurs $A$ et $B$. D'un point de
vue applicatif, ces techniques sont \'etudi\'ees \`a la fois pour des usages
cr\'eatifs (animation, cin\'ema) et pour leurs implications en s\'ecurit\'e
biom\'etrique, notamment les attaques par morphing sur les syst\`emes de
v\'erification de passeports.

Parall\`element, l'entra\^\i{}nement de mod\`eles de reconnaissance faciale soul\`eve
des questions fortes de confidentialit\'e : un attaquant peut-il d\'eterminer
si une image pr\'ecise a fait partie de la base d'entra\^\i{}nement d'un mod\`ele
donn\'e~? C'est pr\'ecis\'ement l'objectif des Membership Inference Attacks (MIA).

Notre projet s'articule autour de ces deux axes~:
\begin{itemize}
  \item construire des pipelines de morphing g\'eom\'etrique contr\^ol\'e,
        puis g\'en\'erer de grands jeux de donn\'ees de visages fictifs
        (identit\'es synth\'etiques) ;
  \item entra\^\i{}ner un r\'eseau MobileNetV2 sur ces identit\'es fictives et
        \'etudier la vuln\'erabilit\'e du mod\`ele face \`a une attaque MIA.
\end{itemize}

Nous avons progressivement \'evolu\'e :
\begin{enumerate}
  \item d'un prototype simple de morphing (sur un petit jeu de visages
        align\'es) vers un pipeline plus robuste sur des visages de
        meilleure qualit\'e ;
  \item d'un dataset interne \texttt{big\_dataset\_alpha} vers un dataset
        synth\'etique d\'eriv\'e de LFW, \texttt{big\_dataset\_lfw} ;
  \item d'une simple g\'en\'eration d'images morph\'ees vers un sc\'enario complet
        \og classification + attaque MIA \fg.
\end{enumerate}

%==============================================================================
\section{Morphing G\'eom\'etrique de Visages}
%==============================================================================

\subsection{Prototype initial sur un petit jeu de visages}

Avant d'industrialiser le pipeline, nous avons mis en place un prototype
sur un petit jeu de visages align\'es. L'objectif \'etait de valider les
briques de base :
\begin{itemize}
  \item d\'etection de points de rep\`ere (landmarks) sur des visages
        centr\'es et sans forte variation de pose ;
  \item triangulation de Delaunay sur ces points pour obtenir une
        d\'ecomposition robuste du visage en triangles ;
  \item warping affine triangle par triangle et m\'elange (alpha-blending)
        entre les deux visages.
\end{itemize}

Ce prototype nous a permis de v\'erifier rapidement que, sur des visages bien
align\'es et de petite taille, le morphing g\'eom\'etrique classique produit des
r\'esultats satisfaisants. Les difficult\'es principales apparaissent d\`es que
l'on augmente la variabilit\'e du dataset (poses, expressions, \'eclairage, \dots),
ce qui a motiv\'e la suite du travail.

\subsection{Pipeline g\'en\'eral de morphing}

Dans la suite du projet (dossier \texttt{simple\_morph}), nous avons adopt\'e
une architecture g\'en\'erique inspir\'ee des travaux classiques sur les
68 landmarks dlib et la triangulation de Delaunay.

Pour deux images sources $I_A$ et $I_B$, le pipeline est le suivant~:
\begin{enumerate}
  \item redimensionner $I_A$ et $I_B$ \`a une taille fixe $(H, W)$ pour
        avoir une g\'eom\'etrie commune ;
  \item d\'etecter les 68 landmarks sur chaque visage avec
        \texttt{shape\_predictor\_68\_face\_landmarks.dat} ;
  \item ajouter des points de bord (coins de l'image et milieux
        des bords) afin de stabiliser la triangulation jusque dans le fond ;
  \item calculer l'ensemble moyen de points $L_{\text{avg}} = (L_A + L_B)/2$
        et construire la triangulation de Delaunay sur ces points ;
  \item pour un coefficient $\alpha \in [0,1]$, interpoler les points
        \[
           L_\alpha = (1-\alpha)\,L_A + \alpha\,L_B ;
        \]
  \item pour chaque triangle de la triangulation, calculer une
        transformation affine qui envoie le triangle de $A$ (resp.
        de $B$) vers sa position correspondante dans $L_\alpha$, puis
        warper localement les pixels ;
  \item combiner les deux images warp\'ees par alpha-blending, en limitant
        le m\'elange \`a l'int\'erieur d'un masque de visage doux afin d'\'eviter
        de m\'elanger les fonds et les cheveux.
\end{enumerate}

En notation compacte, si l'on note $I_A'$ et $I_B'$ les images warp\'ees
dans la g\'eom\'etrie interm\'ediaire, l'image morph\'ee $I_M$ s'\'ecrit
\[
I_M = (1-\alpha)\,I_A' + \alpha\,I_B'.
\]

\subsection{Masque de visage et fusion contr\^ol\'ee}

Un probl\`eme r\'ecurrent dans le morphing na\:if est le m\'elange du fond et des
cheveux, qui g\'en\`ere des artefacts tr\`es visibles. Pour limiter cela, nous
construisons un \emph{masque de visage} \`a partir des seuls points anatomiques
(68 landmarks) sans les points de bord~:
\begin{itemize}
  \item calcul de l'enveloppe convexe des 68 points ;
  \item remplissage de ce polygone (masque binaire) ;
  \item l\'eg\`ere \"r\'eduction\" (\'erosion) + flou gaussien pour obtenir un masque
        \og doux \fg.
\end{itemize}

L'image finale est alors :
\[
\text{composite} = \text{morph} \times \text{masque} +
                   \text{fond\_B} \times (1 - \text{masque}),
\]
où \texttt{fond\_B} est simplement l'image $B$ redimensionn\'ee.

\subsection{G\'en\'eration d'identit\'es multiples et dataset
            \texttt{big\_dataset\_alpha}}

\`A partir de ce pipeline, nous avons construit un premier grand jeu
de donn\'ees fictif \texttt{big\_dataset\_alpha}. L'id\'ee est la suivante~:
\begin{itemize}
  \item disposer de dossiers \texttt{images/enfant},
        \texttt{images/Homme}, \texttt{images/Femme} contenant des
        visages relativement homog\`enes ;
  \item ne g\'en\'erer que des morphs \emph{intra--groupe}
        (enfant--enfant, homme--homme, femme--femme) pour \'eviter les
        d\'eformations extr\^emes (adulte + enfant, etc.) ;
  \item pour chaque paire $(A,B)$ compatible, g\'en\'erer plusieurs morphs
        en faisant varier $\alpha \in \{0.4, 0.5, 0.7\}$, ce qui cr\'ee
        plusieurs identit\'es synth\'etiques distinctes \`a partir des m\^emes
        donneurs.
\end{itemize}

Les morphs de base sont stock\'es dans un dossier
\texttt{morph\_identities\_alpha} avec des noms codant les donneurs et
la valeur de $\alpha$.

Pour disposer de suffisamment d'exemples par identit\'e, nous appliquons
ensuite un script d'augmentation \texttt{augment\_identities.py} qui
cr\'e\'e, pour chaque morph de base, une copie originale + $N$ augmentations
l\'eg\`eres (rotation $\pm 5^\circ$, petites translations, jitter de
contraste/luminosit\'e, bruit gaussien, l\'eger flou ponctuel). Avec
plusieurs centaines de morphs de base et $N = 30$ augmentations, nous
obtenons plus de 23\,000 images fictives dans
\texttt{big\_dataset\_alpha}.

\subsection{Difficult\'es rencontr\'ees sur le morphing}

Les principales difficult\'es ont \'et\'e~:
\begin{itemize}
  \item \textbf{\'Echecs de d\'etection de landmarks} : certaines images
        (poses tr\`es de profil, occlusions, lumi\`ere tr\`es faible)
        provoquaient un \'echec ou une mauvaise localisation des points.
        Nous avons limit\'e l'impact en filtrant les paires trop
        probl\'ematiques et en ajoutant un fallback (grille r\'eguli\`ere)
        quand la d\'etection \'echoue.
  \item \textbf{M\'elange adulte/enfant et poses incompatibles}~:
        les premiers essais m\'elangeant des visages tr\`es diff\'erents
        donnaient des morphs irr\'ealistes (yeux d\'edoubl\'es, cr\^ane
        d\'eform\'e). La solution a \'et\'e de s\'eparer les jeux d'images par
        groupes homog\`enes (enfant / homme / femme) et d'imposer des
        morphs uniquement intra--groupe.
  \item \textbf{Artefacts aux fronti\`eres du visage}~:
        m\^eme avec la triangulation, des discontinuit\'es restaient
        visibles au niveau des contours du visage et des cheveux.
        Nous les avons r\'eduits gr\^ace au masque flout\'e et \`a un
        l\'eger \emph{sharpening} final.
\end{itemize}

%==============================================================================
\section{Base Synth\'etique LFW et Triptyques A $\mid$ C $\mid$ B}
%==============================================================================

\subsection{S\'election d'identit\'es dans LFW}

Dans une seconde phase, nous avons voulu reconstruire un pipeline
similaire \`a partir de la base publique Labeled Faces in the Wild (LFW).
L'objectif est de disposer d'identit\'es bien identifi\'ees, avec de
nombreuses photos par personne, pour construire des identit\'es
\emph{fictives} par morphing.

Nous proc\'edons ainsi :
\begin{enumerate}
  \item t\'el\'echargement de LFW via \texttt{fetch\_lfw\_people}
        (\texttt{scikit-learn}) ;
  \item filtrage pour ne garder que les identit\'es avec au moins
        30 images ;
  \item s\'election de 10 identit\'es parmi les plus fr\'equentes ;
  \item export des images correspondantes dans
        \texttt{images/lfw\_person\_01}, \dots,
        \texttt{images/lfw\_person\_10}.
\end{enumerate}

Nous formons ensuite 5 paires d'identit\'es r\'eelles :
\[
(01,02),\ (03,04),\ (05,06),\ (07,08),\ (09,10).
\]

Pour chaque paire $(A,B)$, nous construisons 50 couples d'images
$(A_i,B_i)$ en parcourant les fichiers tri\'es par nom, puis nous
appliquons le pipeline de morphing g\'eom\'etrique avec $\alpha = 0{,}5$
pour obtenir une identit\'e interm\'ediaire $C_i$.

\subsection{Triptyques visuels A $\mid$ C $\mid$ B}

Afin de documenter clairement les morphs utilis\'es, nous g\'en\'erons
pour chaque couple $(A_i,B_i)$ un panneau horizontal montrant le
triptyque $(A_i, C_i, B_i)$. Le script
\texttt{create\_lfw\_triptychs.py} enregistre ces panneaux dans
\texttt{..\lfw\_morph\_comparison/}.

\begin{figure}[H]
  \centering
  % Exemple de triptyques A|C|B
  \includegraphics[width=0.9\textwidth]{../lfw_morph_comparison/morph_lfw_01_02/panel_img_001__img_001__a050_pair01.png}\\[4pt]
  \includegraphics[width=0.9\textwidth]{../lfw_morph_comparison/morph_lfw_03_04/panel_img_001__img_001__a050_pair01.png}\\[4pt]
  \includegraphics[width=0.9\textwidth]{../lfw_morph_comparison/morph_lfw_05_06/panel_img_002__img_002__a050_pair02.png}
  \caption{Exemples de triptyques $A \mid C \mid B$ (gauche : donneur~A,
           centre : morph $C$ avec $\alpha = 0{,}5$, droite : donneur~B)
           pour quelques paires d'identit\'es LFW.}
  \label{fig:lfw-triptychs}
\end{figure}

Ces figures servent de \og preuve visuelle \fg{} de la qualit\'e des morphs
fournis et de base \`a la construction du dataset synth\'etique
\texttt{big\_dataset\_lfw}.

%==============================================================================
\section{Dataset \texttt{big\_dataset\_lfw} et T\^ache de Classification}
%==============================================================================

\subsection{Construction du dataset synth\'etique}

\`A partir des 250 morphs de base (5 paires d'identit\'es r\'eelles
$\times 50$ couples d'images), nous construisons un dataset
\emph{purement fictif} destin\'e \`a la reconnaissance faciale :
chaque morph de base d\'efinit une identit\'e synth\'etique distincte.

Comme pour \texttt{big\_dataset\_alpha}, nous appliquons une
augmentation de donn\'ees contr\^ol\'ee :
\begin{itemize}
  \item pour chaque morph de base $C_i$, nous gardons l'image
        originale ;
  \item nous g\'en\'erons $n_{\text{aug}} = 7$ augmentations l\'eg\`eres
        (rotation, translation, jitter de luminosit\'e/contraste,
        bruit, flou) ;
  \item au total, chaque identit\'e synth\'etique dispose donc de
        $1 + 7 = 8$ images.
\end{itemize}

Le dataset complet \texttt{big\_dataset\_lfw} contient ainsi
\[
250\ \text{identit\'es} \times 8\ \text{images}
= 2000\ \text{images fictives}.
\]

Les identit\'es sont inf\'er\'ees \`a partir du pr\'efixe du nom de fichier
(avent les suffixes \texttt{\_orig} / \texttt{\_augXXX}).

\subsection{T\^ache de classification}

La t\^ache principale est une classification multi-classes : \`a partir
 d'une image synth\'etique $x$, le mod\`ele doit pr\'edire l'identit\'e
$y \in \{1, \dots, 250\}$. Nous utilisons un MobileNetV2 pr\'e-entra\^\i{}n\'e
sur ImageNet, dont la derni\`ere couche enti\`erement connect\'ee est
remplac\'ee par une couche lin\'eaire de dimension 250.

Le pr\'etraitement des images suit les pratiques courantes :
\begin{itemize}
  \item redimensionnement en $256\times 256$ puis recadrage al\'eatoire
        en $224\times 224$ pour l'entra\^\i{}nement
        (\emph{RandomResizedCrop}) ;
  \item \textit{horizontal flip} al\'eatoire ;
  \item normalisation par les moyennes / \'ecarts-types d'ImageNet.
\end{itemize}

Nous utilisons l'optimiseur Adam (taux d'apprentissage $10^{-3}$,
\emph{weight decay} $10^{-4}$) et une entropie crois\'ee multi-classe.

\subsection{Split 80\,\% / 20\,\% par identit\'e}

Pour r\'epondre \`a la consigne \og 80\,\% des images pour l'entra\^\i{}nement
et 20\,\% pour le test, par identit\'e \fg{}, le split est effectu\'e
\emph{par classe} :
\begin{itemize}
  \item pour chaque identit\'e $k$, nous m\'elangeons al\'eatoirement les 8
        indices d'images disponibles ;
  \item environ 80\,\% (6 ou 7 images) sont allou\'ees \`a l'ensemble
        d'entra\^\i{}nement ;
  \item les 20\,\% restantes (1 ou 2 images) sont allou\'ees \`a
        l'ensemble de validation / test.
\end{itemize}

Sur l'ensemble du dataset~:
\[
\text{train} \approx 1500\ \text{images}, \quad
\text{val}   \approx  500\ \text{images},
\]
r\'eparties sur 250 identit\'es.

\subsection{R\'esultats de classification}

Malgr\'e une architecture relativement l\'eg\`ere (MobileNetV2) et un
entra\^\i{}nement sur CPU, la t\^ache est \og facile \fg{} pour le r\'eseau car
les identit\'es sont bien s\'epar\'ees et chaque identit\'e dispose de
plusieurs images augment\'ees.

Un entra\^\i{}nement typique sur 5 \''epoques donne :
\begin{itemize}
  \item \textbf{\'Epoque 1} : $\text{train\_acc} \approx 10{,}1\,\%$,
        $\text{val\_acc} \approx 49{,}4\,\%$ ;
  \item \textbf{\'Epoque 2} : $\text{train\_acc} \approx 76{,}7\,\%$,
        $\text{val\_acc} \approx 98{,}4\,\%$ ;
  \item \textbf{\'Epoque 3} : $\text{train\_acc} \approx 99{,}6\,\%$,
        $\text{val\_acc} = 100{,}0\,\%$ ;
  \item \textbf{\'Epoques 4--5} : $\text{train\_acc} \approx 100\,\%$,
        $\text{val\_acc} = 100\,\%$.
\end{itemize}

Le meilleur mod\`ele (en termes de pr\'ecision sur la validation) est
sauvegard\'e dans le fichier
\texttt{mobilenet\_big\_dataset\_alpha.pth}.

\subsection{Difficult\'es rencontr\'ees pour la classification}

Les principales difficult\'es n'ont pas \'et\'e d'atteindre une bonne
performance, mais de garantir un split compatible avec la suite MIA~:
\begin{itemize}
  \item il a fallu s'assurer que le split 80/20 \'etait bien r\'ealis\'e
        \emph{par classe} pour \'eviter que certaines identit\'es soient
        uniquement en train ou uniquement en test ;
  \item il a \'egalement fallu enregistrer explicitement les indices
        des images utilis\'ees pour l'entra\^\i{}nement et celles
        r\'eserv\'ees \`a la validation, sous la forme du fichier
        \texttt{membership\_split\_big\_dataset\_lfw.npz}, afin de
        pouvoir les r\'eutiliser pour l'attaque MIA.
\end{itemize}

%==============================================================================
\section{Pr\'eparation et R\'esultats de l'Attaque MIA}
%==============================================================================
%
\subsection{Principe de l’attaque Membership Inference}

Une attaque de type Membership Inference Attack (MIA) cherche \`a
savoir, pour une image $x$, si celle-ci a servi \`a l'entra\^\i{}nement
du mod\`ele (\og member \fg) ou si elle n'a \'et\'e vue qu'en test (\og
non-member \fg). Intuitivement, un mod\`ele trop confiant et trop
\og sur-appris \fg{} aura tendance \`a produire des pr\'edictions
plus \og s\^ures \fg{} (confiance \'elev\'ee, faible loss) sur les
exemples d'entra\^\i{}nement que sur les exemples de test.

Dans notre cas, nous disposons d\'ej\`a de la s\'eparation exacte :
\begin{itemize}
  \item \texttt{train\_indices} : indices des images ayant servi \`a
        l'entra\^\i{}nement (members) ;
  \item \texttt{val\_indices} : indices des images de validation/
        test (non-members).
\end{itemize}

L'attaque retenue est une attaque na\:ive par seuil sur la perte :
\begin{enumerate}
  \item pour chaque image du dataset, nous calculons la
        cross-entropie entre la sortie du mod\`ele et le label vrai ;
  \item nous construisons la distribution des pertes pour les
        membres et pour les non-membres ;
  \item nous balayons un ensemble de seuils $\tau$ possibles et,
        pour chacun, nous d\'ecidons 
        \og member \fg{} si $\text{loss}(x) \le \tau$,
        \og non-member \fg{} sinon ;
  \item nous choisissons le seuil qui maximise l’exactitude de
        l’attaque ou la \emph{balanced accuracy}
        (moyenne de TPR et TNR).
\end{enumerate}

\subsection{Mise en place pratique}

Le script \texttt{mia\_attack.py} r\'ealise les \'etapes suivantes :
\begin{itemize}
  \item chargement du dataset \texttt{big\_dataset\_lfw} avec une
        transformation de validation (redimensionnement +
        recadrage central $224\times 224$, normalisation) ;
  \item chargement du mod\`ele entra\^\i{}n\'e
        \texttt{mobilenet\_big\_dataset\_alpha.pth} ;
  \item calcul, pour chaque image, de la cross-entropie et de la
        confiance maximale (max softmax) ;
  \item s\'eparation des pertes en deux vecteurs :
        \texttt{member\_losses} (indices train) et
        \texttt{nonmember\_losses} (indices val) ;
  \item balayage de seuils pour trouver $\tau^\star$ qui maximise
        la balanced accuracy.
\end{itemize}

\subsection{R\'esultats obtenus et objectif atteint}

Avec le split par identit\'e d\'ecrit plus haut (environ 1500 members
et 500 non-members), nous obtenons typiquement :
\begin{itemize}
  \item moyenne des pertes membres $\mu_\text{mem} \approx 0{,}021$ ;
  \item moyenne des pertes non-members $\mu_\text{non} \approx 0{,}031$ ;
  \item meilleur seuil $\tau^\star \approx 0{,}16$ sur la loss ;
  \item \textbf{balanced accuracy} $\approx 50{,}6\,\%$ ;
  \item TPR tr\`es \'elev\'ee mais TNR tr\`es faible (l’attaquant
        confond la plupart des non-membres avec des membres).
\end{itemize}

L'objectif du projet \'etait d'obtenir une balanced accuracy
\emph{inf\'erieure ou \'egale \`a 55\,\%} pour l'attaque MIA, c'est-\`a-dire
une attaque proche du hasard (50\,\%). Le r\'esultat obtenu
($\approx 50{,}6\,\%$) satisfait donc cette contrainte :
dans ces conditions, l'attaque na\:ive par seuil sur la loss
n'arrive pas vraiment \`a distinguer les membres des non-membres.

\subsection{Difficult\'es sp\'ecifiques \`a MIA}

Sur cette partie, la difficult\'e principale a \'et\'e de comprendre
comment le choix du split et du dataset influen\c{c}ait la puissance
de l'attaque :
\begin{itemize}
  \item avec des splits inadapt\'es (par exemple des identit\'es
        compl\`etes dans le train mais absentes du test, ou l’inverse),
        on peut donner un avantage artificiel \`a l’attaquant ;
  \item il a fallu v\'erifier que la \emph{balanced accuracy} \'etait
        bien mesur\'ee sur un ensemble \'equilibr\'e members / non-membres,
        pour ne pas se laisser tromper par une accuracy globale
        domin\'ee par la classe majoritaire.
\end{itemize}

Apr\`es plusieurs essais et corrections du split, nous avons obtenu un
sc\'enario coh\'erent o\`u l’attaque MIA na\:ive reste proche du hasard,
malgr\'e un mod\`ele de classification quasi parfait.

%==============================================================================
\section{Synth\`ese et Perspectives}
%==============================================================================

\subsection{Bilan global}

Le projet a permis de mettre en place un pipeline complet allant :
\begin{itemize}
  \item du morphing g\'eom\'etrique de visages (landmarks dlib,
        triangulation de Delaunay, warping affine, masque de visage,
        alpha-blending) ;
  \item \`a la g\'en\'eration de grands jeux de donn\'ees de visages
        fictifs (\texttt{big\_dataset\_alpha} puis
        \texttt{big\_dataset\_lfw}) ;
  \item \`a l'entra\^\i{}nement d'un MobileNetV2 pour la reconnaissance
        d'identit\'es synth\'etiques (250 classes, 2000 images) ;
  \item jusqu'\`a la mise en \oe uvre et l'analyse d'une attaque
        Membership Inference, avec un objectif explicite de
        balanced accuracy $\le 55\,\%$.
\end{itemize}

Les r\'esultats obtenus montrent qu'il est possible :
\begin{enumerate}
  \item de g\'en\'erer des morphs visuellement plausibles en grande
        quantit\'e, \`a condition de filtrer les paires trop extr\^emes ;
  \item d'entra\^\i{}ner rapidement un CNN l\'eger qui atteint
        $100\,\%$ de pr\'ecision sur la t\^ache de classification
        d'identit\'es fictives ;
  \item de concevoir un protocole MIA o\`u, malgr\'e ce tr\`es bon score
        de classification, l'attaque na\:ive par seuil sur la loss
        reste proche du hasard.
\end{enumerate}

\subsection{Perspectives d’am\'elioration}

Plusieurs pistes d'am\'elioration ou d'extensions sont possibles :
\begin{itemize}
  \item \textbf{Morphing plus avanc\'e} : int\'egrer des mod\`eles
        g\'en\'eratifs (GANs, diffusion) pour corriger les artefacts
        du morphing g\'eom\'etrique et \og r\'einventer \fg{} les
        d\'etails manquants (cheveux, texture de peau, arri\`ere-plan) ;
  \item \textbf{Morphing 3D} : utiliser un mod\`ele 3DMM pour reconstruire
        une g\'eom\'etrie 3D du visage avant morphing, ce qui faciliterait
        la gestion des poses extr\^emes ;
  \item \textbf{Attaques MIA plus sophistiqu\'ees} : au-del\`a d’un simple
        seuil sur la loss, tester des attaques apprises (entra\^\i{}ner un
        \og mod\`ele attaquant \fg{} sur des features comme la loss,
        la confiance, l’entropie de la sortie, etc.) ;
  \item \textbf{\'Etude syst\'ematique du compromis
        performance / confidentialit\'e} : faire varier la taille du
        mod\`ele, le degr\'e de r\'egularisation, la taille du dataset,
        et observer l’impact conjoint sur la pr\'ecision de
        classification et sur la puissance d’une MIA.
\end{itemize}

\bigskip

En conclusion, le projet a permis d'explorer de bout en bout la cha\^\i{}ne
\emph{morphing $\rightarrow$ dataset fictif $\rightarrow$
CNN de reconnaissance $\rightarrow$ attaque MIA}, en partant de
prototypes simples de morphing pour aboutir \`a un sc\'enario exp\'erimental
complet, reproductible et riche en enseignements \`a la fois sur la
qualit\'e visuelle des morphs et sur les questions de vie priv\'ee li\'ees
\`a l'entra\^\i{}nement des mod\`eles.

\end{document}
