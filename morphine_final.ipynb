{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import bz2\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "# Télécharger dataset\n",
    "path = kagglehub.dataset_download(\"sidharthangn/celebrity-face-dataset-augmented\")\n",
    "print(\"Dataset:\", path)\n",
    "\n",
    "# Config AMÉLIORÉE\n",
    "SIZE = 256  # ✅ Plus grande résolution (était 128)\n",
    "ALPHA_INTRA = 0.5\n",
    "ALPHA_INTER = 0.5\n",
    "NUM_INTRA_PER_PERSON = 30\n",
    "MIN_IMAGES_PER_PERSON = 6\n",
    "\n",
    "# Dossiers\n",
    "OUTPUT_DIR = Path(\"./2stage_morphed_database_HQ\")\n",
    "INTRA_DIR = OUTPUT_DIR / \"stage1_intra_morphs\"\n",
    "INTER_DIR = OUTPUT_DIR / \"stage2_inter_morphs\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "INTRA_DIR.mkdir(exist_ok=True)\n",
    "INTER_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "LOCAL_DATA_DIR = Path(\"./dlib_models\")\n",
    "LOCAL_DATA_DIR.mkdir(exist_ok=True)\n",
    "PREDICTOR_PATH = LOCAL_DATA_DIR / \"shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# Dlib\n",
    "if not PREDICTOR_PATH.exists():\n",
    "    print(\"Téléchargement Dlib...\")\n",
    "    url = \"http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\"\n",
    "    compressed = LOCAL_DATA_DIR / \"temp.bz2\"\n",
    "    urllib.request.urlretrieve(url, compressed)\n",
    "    with bz2.BZ2File(compressed, 'rb') as f_in:\n",
    "        with open(PREDICTOR_PATH, 'wb') as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "    compressed.unlink()\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(str(PREDICTOR_PATH))\n",
    "print(\"[OK] Dlib chargé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = defaultdict(list)\n",
    "for person_dir in Path(path).rglob(\"*\"):\n",
    "    if person_dir.is_dir():\n",
    "        images = list(person_dir.glob(\"*.jpg\")) + list(person_dir.glob(\"*.png\"))\n",
    "        if len(images) >= MIN_IMAGES_PER_PERSON:\n",
    "            persons[person_dir.name] = [str(img) for img in images]\n",
    "\n",
    "person_list = list(persons.keys())\n",
    "n_persons = len(person_list)\n",
    "\n",
    "print(f\"\\n[OK] {n_persons} personnes trouvées\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph_triangle(img1, img2, img_morphed, t1, t2, t_morphed, alpha):\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "    r = cv2.boundingRect(np.float32([t_morphed]))\n",
    "\n",
    "    if r1[2] <= 0 or r1[3] <= 0 or r2[2] <= 0 or r2[3] <= 0 or r[2] <= 0 or r[3] <= 0:\n",
    "        return\n",
    "\n",
    "    t1_rect = [(t1[i][0] - r1[0], t1[i][1] - r1[1]) for i in range(3)]\n",
    "    t2_rect = [(t2[i][0] - r2[0], t2[i][1] - r2[1]) for i in range(3)]\n",
    "    t_rect = [(t_morphed[i][0] - r[0], t_morphed[i][1] - r[1]) for i in range(3)]\n",
    "\n",
    "    img1_rect = img1[r1[1]:r1[1]+r1[3], r1[0]:r1[0]+r1[2]]\n",
    "    img2_rect = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]]\n",
    "\n",
    "    if img1_rect.size == 0 or img2_rect.size == 0:\n",
    "        return\n",
    "\n",
    "    size_rect = (r[2], r[3])\n",
    "\n",
    "    warp_img1 = apply_affine_transform(img1_rect, t1_rect, t_rect, size_rect)\n",
    "    warp_img2 = apply_affine_transform(img2_rect, t2_rect, t_rect, size_rect)\n",
    "\n",
    "    # ✅ CORRECTION: Blend ADDITIF au lieu de moyenne\n",
    "    img_rect = (1.0 - alpha) * warp_img1 + alpha * warp_img2\n",
    "    \n",
    "    # ✅ BOOST de luminosité sur le triangle morphé\n",
    "    img_rect = np.clip(img_rect * 1.0, 0, 255)  # Garder les valeurs\n",
    "\n",
    "    mask = np.zeros((r[3], r[2]), dtype=np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(t_rect), 1.0, cv2.LINE_AA, 0)\n",
    "\n",
    "    y, x, w_rect, h_rect = r[1], r[0], r[2], r[3]\n",
    "    \n",
    "    # ✅ Composite sans assombrir\n",
    "    for c in range(3):  # Pour chaque canal BGR\n",
    "        img_morphed[y:y+h_rect, x:x+w_rect, c] = \\\n",
    "            img_morphed[y:y+h_rect, x:x+w_rect, c] * (1 - mask) + \\\n",
    "            img_rect[:, :, c] * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph_faces(img_path_a, img_path_b, alpha=0.5):\n",
    "    \"\"\"Morphe 2 images - VERSION LUMINEUSE\"\"\"\n",
    "    imgA = cv2.imread(str(img_path_a))\n",
    "    imgB = cv2.imread(str(img_path_b))\n",
    "    \n",
    "    if imgA is None or imgB is None:\n",
    "        return None\n",
    "    \n",
    "    # Resize\n",
    "    imgA_resized = cv2.resize(imgA, (SIZE, SIZE), interpolation=cv2.INTER_LANCZOS4)\n",
    "    imgB_resized = cv2.resize(imgB, (SIZE, SIZE), interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    imgA_gray = cv2.cvtColor(imgA_resized, cv2.COLOR_BGR2GRAY)\n",
    "    imgB_gray = cv2.cvtColor(imgB_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # ✅ IMPORTANT: Garder en float32 SANS normalisation\n",
    "    imgA_color = imgA_resized.astype(np.float32)\n",
    "    imgB_color = imgB_resized.astype(np.float32)\n",
    "\n",
    "    ptsA = prepare_points_for_image(imgA_gray, SIZE, SIZE)\n",
    "    ptsB = prepare_points_for_image(imgB_gray, SIZE, SIZE)\n",
    "\n",
    "    points_morphed = (1.0 - alpha) * ptsA + alpha * ptsB\n",
    "    points_morphed = clamp_points(points_morphed, SIZE, SIZE)\n",
    "\n",
    "    rect = (0, 0, SIZE, SIZE)\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "\n",
    "    for p in points_morphed:\n",
    "        x, y = float(p[0]), float(p[1])\n",
    "        if 0 <= x < SIZE and 0 <= y < SIZE:\n",
    "            try:\n",
    "                subdiv.insert((x, y))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    triangle_list = subdiv.getTriangleList()\n",
    "\n",
    "    tri_indices = []\n",
    "    for t in triangle_list:\n",
    "        tri_pts = [(t[0], t[1]), (t[2], t[3]), (t[4], t[5])]\n",
    "        inds = []\n",
    "        valid = True\n",
    "        for p in tri_pts:\n",
    "            idx = find_point_index(points_morphed, p, tol=3.0)\n",
    "            if idx is None:\n",
    "                valid = False\n",
    "                break\n",
    "            inds.append(idx)\n",
    "        if valid and len(set(inds)) == 3:\n",
    "            tri_indices.append(tuple(inds))\n",
    "\n",
    "    tri_indices = list(set(tri_indices))\n",
    "\n",
    "    # ✅ INITIALISER avec une image BLANCHE (255) au lieu de NOIRE (0)\n",
    "    img_morphed = np.full_like(imgA_color, 255.0, dtype=np.float32)\n",
    "\n",
    "    for tri in tri_indices:\n",
    "        i1, i2, i3 = tri\n",
    "        tA = [ptsA[i1], ptsA[i2], ptsA[i3]]\n",
    "        tB = [ptsB[i1], ptsB[i2], ptsB[i3]]\n",
    "        tM = [points_morphed[i1], points_morphed[i2], points_morphed[i3]]\n",
    "\n",
    "        if not (triangle_completely_inside(tA, SIZE, SIZE) and \n",
    "                triangle_completely_inside(tB, SIZE, SIZE) and \n",
    "                triangle_completely_inside(tM, SIZE, SIZE)):\n",
    "            continue\n",
    "\n",
    "        morph_triangle(imgA_color, imgB_color, img_morphed, tA, tB, tM, alpha)\n",
    "\n",
    "    morph_result = np.clip(img_morphed, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # ✅ Post-traitement SIMPLE et EFFICACE\n",
    "    # 1. Vérifier luminosité\n",
    "    mean_brightness = np.mean(cv2.cvtColor(morph_result, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # 2. Corriger si trop sombre\n",
    "    if mean_brightness < 100:\n",
    "        factor = 100.0 / max(mean_brightness, 1)\n",
    "        morph_result = cv2.convertScaleAbs(morph_result, alpha=min(factor, 2.0), beta=0)\n",
    "    \n",
    "    # 3. Égalisation adaptative\n",
    "    morph_lab = cv2.cvtColor(morph_result, cv2.COLOR_BGR2LAB)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    morph_lab[:,:,0] = clahe.apply(morph_lab[:,:,0])\n",
    "    morph_result = cv2.cvtColor(morph_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Vérification finale\n",
    "    if np.mean(morph_result) < 10:\n",
    "        return None\n",
    "    \n",
    "    return morph_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage1_intra_morphing():\n",
    "    \"\"\"ÉTAPE 1: Morphing INTRA-personne\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ÉTAPE 1 - MORPHING INTRA-PERSONNE (HAUTE QUALITÉ)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    intra_morphs = defaultdict(list)\n",
    "    stats = {\"successful\": 0, \"failed\": 0}\n",
    "    \n",
    "    for person_name in tqdm(person_list, desc=\"Étape 1 - Intra\"):\n",
    "        clean_name = sanitize_name(person_name)\n",
    "        imgs = persons[person_name]\n",
    "        \n",
    "        for n in range(1, NUM_INTRA_PER_PERSON + 1):\n",
    "            try:\n",
    "                img_a, img_b = np.random.choice(imgs, size=2, replace=False)\n",
    "                morph = morph_faces(img_a, img_b, alpha=ALPHA_INTRA)\n",
    "                \n",
    "                if morph is not None:\n",
    "                    filename = f\"{clean_name}_intra_{n}.png\"\n",
    "                    filepath = INTRA_DIR / filename\n",
    "                    # ✅ Sauvegarde avec compression optimale\n",
    "                    cv2.imwrite(str(filepath), morph, [cv2.IMWRITE_PNG_COMPRESSION, 3])\n",
    "                    \n",
    "                    intra_morphs[person_name].append(str(filepath))\n",
    "                    stats[\"successful\"] += 1\n",
    "                else:\n",
    "                    stats[\"failed\"] += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                stats[\"failed\"] += 1\n",
    "    \n",
    "    print(f\"\\n[ÉTAPE 1 TERMINÉE]\")\n",
    "    print(f\"   - Images générées: {stats['successful']}\")\n",
    "    print(f\"   - Échecs: {stats['failed']}\")\n",
    "    \n",
    "    return intra_morphs, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage2_inter_morphing(intra_morphs):\n",
    "    \"\"\"ÉTAPE 2: Morphing INTER-personnes\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ÉTAPE 2 - MORPHING INTER-PERSONNES (HAUTE QUALITÉ)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    stats = {\"successful\": 0, \"failed\": 0}\n",
    "    person_pairs = list(itertools.combinations(person_list, 2))\n",
    "    \n",
    "    print(f\"   - Paires: {len(person_pairs)}\\n\")\n",
    "    \n",
    "    for person_a, person_b in tqdm(person_pairs, desc=\"Étape 2 - Inter\"):\n",
    "        morphs_a = intra_morphs.get(person_a, [])\n",
    "        morphs_b = intra_morphs.get(person_b, [])\n",
    "        \n",
    "        if not morphs_a or not morphs_b:\n",
    "            continue\n",
    "        \n",
    "        clean_a = sanitize_name(person_a)\n",
    "        clean_b = sanitize_name(person_b)\n",
    "        \n",
    "        for i, morph_a in enumerate(morphs_a, 1):\n",
    "            for j, morph_b in enumerate(morphs_b, 1):\n",
    "                try:\n",
    "                    hybrid = morph_faces(morph_a, morph_b, alpha=ALPHA_INTER)\n",
    "                    \n",
    "                    if hybrid is not None:\n",
    "                        filename = f\"{clean_a}-{clean_b}_{i}_{j}.png\"\n",
    "                        filepath = INTER_DIR / filename\n",
    "                        cv2.imwrite(str(filepath), hybrid, [cv2.IMWRITE_PNG_COMPRESSION, 3])\n",
    "                        stats[\"successful\"] += 1\n",
    "                    else:\n",
    "                        stats[\"failed\"] += 1\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    stats[\"failed\"] += 1\n",
    "    \n",
    "    print(f\"\\n[ÉTAPE 2 TERMINÉE]\")\n",
    "    print(f\"   - Images générées: {stats['successful']}\")\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "intra_morphs, stats1 = stage1_intra_morphing()\n",
    "stats2 = stage2_inter_morphing(intra_morphs)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TERMINÉ - HAUTE QUALITÉ\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"ÉTAPE 1: {stats1['successful']} images\")\n",
    "print(f\"ÉTAPE 2: {stats2['successful']} images\")\n",
    "print(f\"TOTAL: {stats1['successful'] + stats2['successful']}\")\n",
    "print(f\"Temps: {elapsed/60:.1f} min\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "\n",
    "# Dossier source\n",
    "DATA_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\2stage_morphed_database_HQ\\stage1_intra_morphs\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DETECTION DES IMAGES DEFORMEES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "image_files = list(DATA_DIR.glob(\"*.png\")) + list(DATA_DIR.glob(\"*.jpg\"))\n",
    "print(f\"Images a analyser: {len(image_files)}\")\n",
    "\n",
    "def detect_artifacts(img):\n",
    "    \"\"\"\n",
    "    Detecte les artefacts dans une image:\n",
    "    - Tourbillons\n",
    "    - Distorsions\n",
    "    - Zones noires anormales\n",
    "    - Bords deformes\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    # 1. Convertir en grayscale\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    \n",
    "    # 2. Detecter les bords (Canny)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    edge_density = np.sum(edges > 0) / edges.size\n",
    "    scores['edge_density'] = edge_density\n",
    "    \n",
    "    # 3. Detecter les zones noires anormales\n",
    "    black_pixels = np.sum(gray < 10) / gray.size\n",
    "    scores['black_ratio'] = black_pixels\n",
    "    \n",
    "    # 4. Variance locale (detecte les distorsions)\n",
    "    kernel_size = 15\n",
    "    local_mean = cv2.blur(gray.astype(np.float32), (kernel_size, kernel_size))\n",
    "    local_sq_mean = cv2.blur((gray.astype(np.float32))**2, (kernel_size, kernel_size))\n",
    "    local_var = local_sq_mean - local_mean**2\n",
    "    var_of_var = np.std(local_var)\n",
    "    scores['var_of_var'] = var_of_var\n",
    "    \n",
    "    # 5. Laplacian (detecte les flous et distorsions)\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    laplacian_var = np.var(laplacian)\n",
    "    scores['laplacian_var'] = laplacian_var\n",
    "    \n",
    "    # 6. Detecter les lignes anormales (Hough)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=30, maxLineGap=10)\n",
    "    n_lines = len(lines) if lines is not None else 0\n",
    "    scores['n_lines'] = n_lines\n",
    "    \n",
    "    # 7. Symetrie du visage (un visage normal est relativement symetrique)\n",
    "    h, w = gray.shape\n",
    "    left_half = gray[:, :w//2]\n",
    "    right_half = cv2.flip(gray[:, w//2:], 1)\n",
    "    \n",
    "    # Ajuster les tailles si necessaire\n",
    "    min_w = min(left_half.shape[1], right_half.shape[1])\n",
    "    left_half = left_half[:, :min_w]\n",
    "    right_half = right_half[:, :min_w]\n",
    "    \n",
    "    symmetry_diff = np.mean(np.abs(left_half.astype(np.float32) - right_half.astype(np.float32)))\n",
    "    scores['asymmetry'] = symmetry_diff\n",
    "    \n",
    "    # 8. Gradient magnitude (detecte les transitions brutales)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    gradient_max = np.max(gradient_mag)\n",
    "    gradient_mean = np.mean(gradient_mag)\n",
    "    scores['gradient_ratio'] = gradient_max / (gradient_mean + 1e-6)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Analyser toutes les images\n",
    "print(\"\\nAnalyse en cours...\")\n",
    "results = []\n",
    "\n",
    "for filepath in image_files:\n",
    "    img = cv2.imread(str(filepath))\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    # Redimensionner pour analyse uniforme\n",
    "    img_resized = cv2.resize(img, (128, 128))\n",
    "    \n",
    "    scores = detect_artifacts(img_resized)\n",
    "    scores['filepath'] = filepath\n",
    "    scores['filename'] = filepath.name\n",
    "    \n",
    "    results.append(scores)\n",
    "\n",
    "print(f\"[OK] {len(results)} images analysees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convertir en DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STATISTIQUES DES METRIQUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Afficher les stats\n",
    "metrics = ['edge_density', 'black_ratio', 'var_of_var', 'laplacian_var', 'asymmetry', 'gradient_ratio']\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\n{metric}:\")\n",
    "    print(f\"   Min: {df[metric].min():.4f}\")\n",
    "    print(f\"   Max: {df[metric].max():.4f}\")\n",
    "    print(f\"   Mean: {df[metric].mean():.4f}\")\n",
    "    print(f\"   Std: {df[metric].std():.4f}\")\n",
    "\n",
    "# Calculer un score de qualite combine\n",
    "# Les images deformees ont souvent:\n",
    "# - Haute edge_density (trop de bords)\n",
    "# - Haute asymmetry (visage deforme)\n",
    "# - Haut gradient_ratio (transitions brutales)\n",
    "# - Haute var_of_var (variance irreguliere)\n",
    "\n",
    "df['quality_score'] = (\n",
    "    (df['edge_density'] - df['edge_density'].mean()) / df['edge_density'].std() +\n",
    "    (df['asymmetry'] - df['asymmetry'].mean()) / df['asymmetry'].std() +\n",
    "    (df['gradient_ratio'] - df['gradient_ratio'].mean()) / df['gradient_ratio'].std() +\n",
    "    (df['var_of_var'] - df['var_of_var'].mean()) / df['var_of_var'].std()\n",
    ")\n",
    "\n",
    "# Les images avec un score eleve sont suspectes\n",
    "threshold = df['quality_score'].mean() + 1.5 * df['quality_score'].std()\n",
    "\n",
    "bad_images = df[df['quality_score'] > threshold]\n",
    "good_images = df[df['quality_score'] <= threshold]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"RESULTAT\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"   - Seuil de qualite: {threshold:.4f}\")\n",
    "print(f\"   - Images OK: {len(good_images)}\")\n",
    "print(f\"   - Images suspectes: {len(bad_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les 20 images les plus suspectes\n",
    "worst_images = df.nlargest(20, 'quality_score')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TOP 20 IMAGES LES PLUS SUSPECTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = 4\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (_, row) in enumerate(worst_images.iterrows()):\n",
    "    if i >= 20:\n",
    "        break\n",
    "    \n",
    "    img = cv2.imread(str(row['filepath']))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"{row['filename'][:15]}\\nScore: {row['quality_score']:.2f}\", fontsize=8, color='red')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(\"Images Suspectes (a verifier)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"suspicious_images.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFichiers suspects:\")\n",
    "for _, row in worst_images.iterrows():\n",
    "    print(f\"   - {row['filename']} (score: {row['quality_score']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les 20 meilleures images\n",
    "best_images = df.nsmallest(20, 'quality_score')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TOP 20 MEILLEURES IMAGES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (_, row) in enumerate(best_images.iterrows()):\n",
    "    if i >= 20:\n",
    "        break\n",
    "    \n",
    "    img = cv2.imread(str(row['filepath']))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"{row['filename'][:15]}\\nScore: {row['quality_score']:.2f}\", fontsize=8, color='green')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(\"Bonnes Images (reference)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"good_images.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher TOUTES les images suspectes pour verification manuelle\n",
    "print(\"=\"*60)\n",
    "print(\"VERIFICATION MANUELLE\")\n",
    "print(\"=\"*60)\n",
    "print(\"Regardez les images et notez celles a supprimer\")\n",
    "\n",
    "# Trier par score decroissant\n",
    "suspicious = df[df['quality_score'] > df['quality_score'].median()].sort_values('quality_score', ascending=False)\n",
    "\n",
    "# Afficher par lots de 25\n",
    "n_per_page = 25\n",
    "n_pages = (len(suspicious) + n_per_page - 1) // n_per_page\n",
    "\n",
    "for page in range(min(3, n_pages)):  # Afficher les 3 premieres pages\n",
    "    start = page * n_per_page\n",
    "    end = min(start + n_per_page, len(suspicious))\n",
    "    \n",
    "    subset = suspicious.iloc[start:end]\n",
    "    \n",
    "    n_rows = 5\n",
    "    n_cols = 5\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (_, row) in enumerate(subset.iterrows()):\n",
    "        img = cv2.imread(str(row['filepath']))\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"{row['filename'][:20]}\\n{row['quality_score']:.1f}\", fontsize=7)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    for i in range(len(subset), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Page {page+1}/{n_pages} - Images a verifier\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"verification_page_{page+1}.png\", dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer les dossiers\n",
    "CLEAN_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\cleaned_morphed_database_v2\")\n",
    "REJECTED_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\rejected_images_v2\")\n",
    "\n",
    "CLEAN_DIR.mkdir(exist_ok=True)\n",
    "REJECTED_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NETTOYAGE AUTOMATIQUE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Seuil plus strict: supprimer les images avec score > mean + 1*std\n",
    "strict_threshold = df['quality_score'].mean() + 1.0 * df['quality_score'].std()\n",
    "\n",
    "good_df = df[df['quality_score'] <= strict_threshold]\n",
    "bad_df = df[df['quality_score'] > strict_threshold]\n",
    "\n",
    "print(f\"Seuil strict: {strict_threshold:.4f}\")\n",
    "print(f\"   - Images a garder: {len(good_df)}\")\n",
    "print(f\"   - Images a rejeter: {len(bad_df)}\")\n",
    "\n",
    "# Copier les bonnes images\n",
    "copied = 0\n",
    "for _, row in good_df.iterrows():\n",
    "    filepath = row['filepath']\n",
    "    img = cv2.imread(str(filepath))\n",
    "    if img is not None:\n",
    "        # Redimensionner a 128x128\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        new_path = CLEAN_DIR / filepath.name\n",
    "        cv2.imwrite(str(new_path), img)\n",
    "        copied += 1\n",
    "\n",
    "# Copier les mauvaises images (pour reference)\n",
    "rejected = 0\n",
    "for _, row in bad_df.iterrows():\n",
    "    filepath = row['filepath']\n",
    "    if filepath.exists():\n",
    "        shutil.copy(str(filepath), str(REJECTED_DIR / filepath.name))\n",
    "        rejected += 1\n",
    "\n",
    "print(f\"\\n[OK] Nettoyage termine!\")\n",
    "print(f\"   - Images copiees: {copied}\")\n",
    "print(f\"   - Images rejetees: {rejected}\")\n",
    "print(f\"   - Dossier propre: {CLEAN_DIR}\")\n",
    "print(f\"   - Dossier rejete: {REJECTED_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifier la data nettoyee\n",
    "clean_files = list(CLEAN_DIR.glob(\"*.png\")) + list(CLEAN_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "# Compter par personne\n",
    "clean_persons = defaultdict(list)\n",
    "for f in clean_files:\n",
    "    name = f.stem\n",
    "    # Extraire le nom de la personne\n",
    "    # Format attendu: NomPersonne_intra_N.png ou NomPersonne_N.png\n",
    "    parts = name.split(\"_\")\n",
    "    if \"intra\" in parts:\n",
    "        idx = parts.index(\"intra\")\n",
    "        person = \"_\".join(parts[:idx])\n",
    "    else:\n",
    "        person = \"_\".join(parts[:-1])\n",
    "    \n",
    "    clean_persons[person].append(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA NETTOYEE - DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nPersonnes: {len(clean_persons)}\")\n",
    "print(f\"Total images: {len(clean_files)}\")\n",
    "\n",
    "print(f\"\\nDistribution par personne:\")\n",
    "for person, files in sorted(clean_persons.items(), key=lambda x: -len(x[1])):\n",
    "    status = \"OK\" if len(files) >= 6 else \"PEU\"\n",
    "    print(f\"   {person}: {len(files)} images [{status}]\")\n",
    "\n",
    "# Filtrer les personnes avec assez d'images\n",
    "MIN_IMAGES = 6\n",
    "valid_persons = {k: v for k, v in clean_persons.items() if len(v) >= MIN_IMAGES}\n",
    "print(f\"\\nPersonnes avec {MIN_IMAGES}+ images: {len(valid_persons)}\")\n",
    "print(f\"Total images valides: {sum(len(v) for v in valid_persons.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dossier source\n",
    "SOURCE_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\2stage_morphed_database_HQ\\stage2_inter_morphs\")\n",
    "\n",
    "image_files = list(SOURCE_DIR.glob(\"*.png\")) + list(SOURCE_DIR.glob(\"*.jpg\"))\n",
    "print(f\"Images source: {len(image_files)}\")\n",
    "\n",
    "# Analyser un echantillon pour trouver les bons seuils\n",
    "sample_size = min(500, len(image_files))\n",
    "sample_files = np.random.choice(image_files, sample_size, replace=False)\n",
    "\n",
    "print(f\"\\nAnalyse de {sample_size} images...\")\n",
    "\n",
    "stats = {\n",
    "    'brightness': [],\n",
    "    'edge_ratio': [],\n",
    "    'asymmetry': [],\n",
    "    'laplacian_var': []\n",
    "}\n",
    "\n",
    "for filepath in sample_files:\n",
    "    img = cv2.imread(str(filepath))\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Brightness\n",
    "    stats['brightness'].append(np.mean(gray))\n",
    "    \n",
    "    # Edge ratio\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    stats['edge_ratio'].append(np.sum(edges > 0) / edges.size)\n",
    "    \n",
    "    # Asymmetry\n",
    "    h, w = gray.shape\n",
    "    left = gray[:, :w//2]\n",
    "    right = cv2.flip(gray[:, w//2:], 1)\n",
    "    min_w = min(left.shape[1], right.shape[1])\n",
    "    stats['asymmetry'].append(np.mean(np.abs(left[:, :min_w].astype(float) - right[:, :min_w].astype(float))))\n",
    "    \n",
    "    # Laplacian variance (blur detection)\n",
    "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    stats['laplacian_var'].append(np.var(lap))\n",
    "\n",
    "# Afficher les statistiques\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTIQUES DES IMAGES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric, values in stats.items():\n",
    "    values = np.array(values)\n",
    "    print(f\"\\n{metric}:\")\n",
    "    print(f\"   Min: {values.min():.4f}\")\n",
    "    print(f\"   Max: {values.max():.4f}\")\n",
    "    print(f\"   Mean: {values.mean():.4f}\")\n",
    "    print(f\"   Std: {values.std():.4f}\")\n",
    "    print(f\"   Percentile 10%: {np.percentile(values, 10):.4f}\")\n",
    "    print(f\"   Percentile 90%: {np.percentile(values, 90):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for i, (metric, values) in enumerate(stats.items()):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    axes[row][col].hist(values, bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[row][col].set_title(f'Distribution: {metric}')\n",
    "    axes[row][col].set_xlabel(metric)\n",
    "    axes[row][col].set_ylabel('Frequence')\n",
    "    axes[row][col].axvline(np.mean(values), color='red', linestyle='--', label=f'Mean: {np.mean(values):.3f}')\n",
    "    axes[row][col].axvline(np.percentile(values, 95), color='green', linestyle='--', label=f'95%: {np.percentile(values, 95):.3f}')\n",
    "    axes[row][col].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"stats_distribution.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n[INFO] Regardez les distributions pour choisir les seuils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier par edge_ratio pour voir ce qui est \"normal\" vs \"distordu\"\n",
    "sample_with_stats = []\n",
    "\n",
    "for filepath in sample_files[:200]:\n",
    "    img = cv2.imread(str(filepath))\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    edge_ratio = np.sum(edges > 0) / edges.size\n",
    "    \n",
    "    sample_with_stats.append((filepath, edge_ratio, img))\n",
    "\n",
    "# Trier par edge_ratio\n",
    "sample_with_stats.sort(key=lambda x: x[1])\n",
    "\n",
    "# Afficher les images avec le PLUS BAS edge_ratio (probablement bonnes)\n",
    "print(\"=\"*60)\n",
    "print(\"IMAGES AVEC EDGE_RATIO BAS (bonnes)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    filepath, edge_ratio, img = sample_with_stats[i]\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axes[i].imshow(img_rgb)\n",
    "    axes[i].set_title(f\"edge={edge_ratio:.3f}\", fontsize=9)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(\"Edge Ratio BAS (probablement bonnes)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les images avec le PLUS HAUT edge_ratio (probablement mauvaises)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMAGES AVEC EDGE_RATIO HAUT (possiblement mauvaises)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    filepath, edge_ratio, img = sample_with_stats[-(i+1)]\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axes[i].imshow(img_rgb)\n",
    "    axes[i].set_title(f\"edge={edge_ratio:.3f}\", fontsize=9)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(\"Edge Ratio HAUT (possiblement mauvaises)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Dossier destination\n",
    "CLEAN_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\final_clean_dataset\")\n",
    "CLEAN_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Supprimer les anciens fichiers\n",
    "for f in CLEAN_DIR.glob(\"*\"):\n",
    "    f.unlink()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NETTOYAGE AVEC SEUILS AJUSTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculer les seuils bases sur les percentiles\n",
    "edge_threshold = np.percentile(stats['edge_ratio'], 90)  # Garder 90% des images\n",
    "brightness_min = np.percentile(stats['brightness'], 5)   # Rejeter les 5% plus sombres\n",
    "asymmetry_threshold = np.percentile(stats['asymmetry'], 95)  # Garder 95%\n",
    "\n",
    "print(f\"\\nSeuils utilises:\")\n",
    "print(f\"   - Edge ratio max: {edge_threshold:.4f}\")\n",
    "print(f\"   - Brightness min: {brightness_min:.4f}\")\n",
    "print(f\"   - Asymmetry max: {asymmetry_threshold:.4f}\")\n",
    "\n",
    "# Appliquer le nettoyage\n",
    "good_images = []\n",
    "bad_images = []\n",
    "\n",
    "for filepath in image_files:\n",
    "    img = cv2.imread(str(filepath))\n",
    "    if img is None:\n",
    "        bad_images.append((filepath, \"corrupted\"))\n",
    "        continue\n",
    "    \n",
    "    img_resized = cv2.resize(img, (128, 128))\n",
    "    gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculer les metriques\n",
    "    brightness = np.mean(gray)\n",
    "    \n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    edge_ratio = np.sum(edges > 0) / edges.size\n",
    "    \n",
    "    h, w = gray.shape\n",
    "    left = gray[:, :w//2]\n",
    "    right = cv2.flip(gray[:, w//2:], 1)\n",
    "    min_w = min(left.shape[1], right.shape[1])\n",
    "    asymmetry = np.mean(np.abs(left[:, :min_w].astype(float) - right[:, :min_w].astype(float)))\n",
    "    \n",
    "    # Criteres de rejet (plus permissifs)\n",
    "    if brightness < brightness_min:\n",
    "        bad_images.append((filepath, \"too_dark\"))\n",
    "    elif edge_ratio > edge_threshold:\n",
    "        bad_images.append((filepath, \"distorted\"))\n",
    "    elif asymmetry > asymmetry_threshold:\n",
    "        bad_images.append((filepath, \"asymmetric\"))\n",
    "    else:\n",
    "        good_images.append(filepath)\n",
    "\n",
    "print(f\"\\nResultats:\")\n",
    "print(f\"   - Images OK: {len(good_images)}\")\n",
    "print(f\"   - Images rejetees: {len(bad_images)}\")\n",
    "\n",
    "# Raisons de rejet\n",
    "reasons = defaultdict(int)\n",
    "for _, reason in bad_images:\n",
    "    reasons[reason] += 1\n",
    "print(f\"\\nRaisons de rejet:\")\n",
    "for reason, count in reasons.items():\n",
    "    print(f\"   - {reason}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COPIE DES IMAGES VALIDES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Organiser par personne\n",
    "persons = defaultdict(list)\n",
    "\n",
    "for filepath in good_images:\n",
    "    name = filepath.stem\n",
    "    \n",
    "    # Extraire le nom de la personne\n",
    "    if \"_intra_\" in name:\n",
    "        person = name.split(\"_intra_\")[0]\n",
    "    elif \"_inter_\" in name:\n",
    "        person = name.split(\"_inter_\")[0]\n",
    "    else:\n",
    "        parts = name.rsplit(\"_\", 1)\n",
    "        person = parts[0] if len(parts) == 2 and parts[1].isdigit() else name\n",
    "    \n",
    "    persons[person].append(filepath)\n",
    "\n",
    "print(f\"Personnes detectees: {len(persons)}\")\n",
    "\n",
    "# Afficher la distribution\n",
    "print(\"\\nDistribution par personne:\")\n",
    "for person, files in sorted(persons.items(), key=lambda x: -len(x[1])):\n",
    "    print(f\"   {person}: {len(files)} images\")\n",
    "\n",
    "# Filtrer les personnes avec assez d'images\n",
    "MIN_IMAGES = 6\n",
    "valid_persons = {k: v for k, v in persons.items() if len(v) >= MIN_IMAGES}\n",
    "\n",
    "print(f\"\\nPersonnes avec {MIN_IMAGES}+ images: {len(valid_persons)}\")\n",
    "print(f\"Total images valides: {sum(len(v) for v in valid_persons.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copier les images\n",
    "MAX_PER_PERSON = 30  # Maximum par personne pour equilibrer\n",
    "\n",
    "copied = 0\n",
    "for person, files in valid_persons.items():\n",
    "    # Limiter le nombre d'images par personne\n",
    "    selected = files[:MAX_PER_PERSON]\n",
    "    \n",
    "    for i, filepath in enumerate(selected, 1):\n",
    "        img = cv2.imread(str(filepath))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            new_filename = f\"{person}_{i}.png\"\n",
    "            new_path = CLEAN_DIR / new_filename\n",
    "            cv2.imwrite(str(new_path), img)\n",
    "            copied += 1\n",
    "\n",
    "print(f\"\\n[OK] {copied} images copiees dans {CLEAN_DIR}\")\n",
    "\n",
    "# Verifier\n",
    "final_files = list(CLEAN_DIR.glob(\"*.png\"))\n",
    "print(f\"[OK] Verification: {len(final_files)} fichiers\")\n",
    "\n",
    "# Compter par personne\n",
    "final_persons = defaultdict(int)\n",
    "for f in final_files:\n",
    "    person = f.stem.rsplit(\"_\", 1)[0]\n",
    "    final_persons[person] += 1\n",
    "\n",
    "print(f\"\\nDataset final:\")\n",
    "print(f\"   - Personnes: {len(final_persons)}\")\n",
    "print(f\"   - Images totales: {len(final_files)}\")\n",
    "print(f\"   - Images par personne: {min(final_persons.values())} - {max(final_persons.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher des exemples\n",
    "final_files = list(CLEAN_DIR.glob(\"*.png\"))\n",
    "\n",
    "if final_files:\n",
    "    n_samples = min(20, len(final_files))\n",
    "    sample_files = np.random.choice(final_files, n_samples, replace=False)\n",
    "    \n",
    "    rows = (n_samples + 4) // 5\n",
    "    fig, axes = plt.subplots(rows, 5, figsize=(15, 3*rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, filepath in enumerate(sample_files):\n",
    "        img = cv2.imread(str(filepath))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(filepath.stem[:15], fontsize=8)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    for i in range(n_samples, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Dataset Final - {len(final_files)} images\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CLEAN_DIR / \"preview.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n[OK] Dataset pret dans: {CLEAN_DIR}\")\n",
    "    print(f\"[OK] Vous pouvez maintenant lancer l'entrainement CNN!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Dossier source\n",
    "DATA_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\final_clean_dataset\")\n",
    "\n",
    "# Compter les images et classes\n",
    "files = list(DATA_DIR.glob(\"*.png\")) + list(DATA_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "persons = defaultdict(int)\n",
    "for f in files:\n",
    "    name = f.stem\n",
    "    # Extraire le nom de la personne\n",
    "    if \"_intra_\" in name:\n",
    "        person = name.split(\"_intra_\")[0]\n",
    "    elif \"_inter_\" in name:\n",
    "        person = name.split(\"_inter_\")[0]\n",
    "    else:\n",
    "        parts = name.rsplit(\"_\", 1)\n",
    "        person = parts[0] if len(parts) == 2 and parts[1].isdigit() else name\n",
    "    persons[person] += 1\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DIAGNOSTIC DU DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nImages totales: {len(files)}\")\n",
    "print(f\"Classes (personnes): {len(persons)}\")\n",
    "print(f\"Images par classe: {min(persons.values())} - {max(persons.values())}\")\n",
    "print(f\"Moyenne: {np.mean(list(persons.values())):.1f}\")\n",
    "\n",
    "# Distribution\n",
    "print(f\"\\nDistribution:\")\n",
    "for person, count in sorted(persons.items(), key=lambda x: -x[1])[:20]:\n",
    "    print(f\"   {person}: {count}\")\n",
    "\n",
    "if len(persons) > 20:\n",
    "    print(f\"   ... et {len(persons) - 20} autres classes\")\n",
    "\n",
    "# Probleme?\n",
    "if len(persons) > 50:\n",
    "    print(f\"\\n[PROBLEME] Trop de classes ({len(persons)})!\")\n",
    "    print(\"   -> Le modele a du mal a apprendre\")\n",
    "    print(\"   -> Solution: Reduire le nombre de classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garder seulement les TOP N personnes avec le plus d'images\n",
    "TOP_N = 14  # Comme le dataset Celebrity original\n",
    "\n",
    "# Trier par nombre d'images\n",
    "sorted_persons = sorted(persons.items(), key=lambda x: -x[1])\n",
    "selected_persons = [p[0] for p in sorted_persons[:TOP_N]]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"SELECTION DES TOP {TOP_N} PERSONNES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, (person, count) in enumerate(sorted_persons[:TOP_N]):\n",
    "    print(f\"   {i+1}. {person}: {count} images\")\n",
    "\n",
    "# Creer le nouveau dossier\n",
    "NEW_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\dataset_top14\")\n",
    "NEW_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Supprimer les anciens fichiers\n",
    "for f in NEW_DIR.glob(\"*\"):\n",
    "    f.unlink()\n",
    "\n",
    "# Copier les images des personnes selectionnees\n",
    "copied = 0\n",
    "for f in files:\n",
    "    name = f.stem\n",
    "    if \"_intra_\" in name:\n",
    "        person = name.split(\"_intra_\")[0]\n",
    "    elif \"_inter_\" in name:\n",
    "        person = name.split(\"_inter_\")[0]\n",
    "    else:\n",
    "        parts = name.rsplit(\"_\", 1)\n",
    "        person = parts[0] if len(parts) == 2 and parts[1].isdigit() else name\n",
    "    \n",
    "    if person in selected_persons:\n",
    "        img = cv2.imread(str(f))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "            # Nouveau nom\n",
    "            idx = sum(1 for x in NEW_DIR.glob(f\"{person}_*.png\")) + 1\n",
    "            new_path = NEW_DIR / f\"{person}_{idx}.png\"\n",
    "            cv2.imwrite(str(new_path), img)\n",
    "            copied += 1\n",
    "\n",
    "print(f\"\\n[OK] {copied} images copiees dans {NEW_DIR}\")\n",
    "\n",
    "# Verifier\n",
    "final_counts = defaultdict(int)\n",
    "for f in NEW_DIR.glob(\"*.png\"):\n",
    "    person = f.stem.rsplit(\"_\", 1)[0]\n",
    "    final_counts[person] += 1\n",
    "\n",
    "print(f\"\\nDataset final:\")\n",
    "for person, count in sorted(final_counts.items()):\n",
    "    print(f\"   {person}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garder seulement les TOP N personnes avec le plus d'images\n",
    "TOP_N = 14  # Comme le dataset Celebrity original\n",
    "\n",
    "# Trier par nombre d'images\n",
    "sorted_persons = sorted(persons.items(), key=lambda x: -x[1])\n",
    "selected_persons = [p[0] for p in sorted_persons[:TOP_N]]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"SELECTION DES TOP {TOP_N} PERSONNES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, (person, count) in enumerate(sorted_persons[:TOP_N]):\n",
    "    print(f\"   {i+1}. {person}: {count} images\")\n",
    "\n",
    "# Creer le nouveau dossier\n",
    "NEW_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\dataset_top14\")\n",
    "NEW_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Supprimer les anciens fichiers\n",
    "for f in NEW_DIR.glob(\"*\"):\n",
    "    f.unlink()\n",
    "\n",
    "# Copier les images des personnes selectionnees\n",
    "copied = 0\n",
    "for f in files:\n",
    "    name = f.stem\n",
    "    if \"_intra_\" in name:\n",
    "        person = name.split(\"_intra_\")[0]\n",
    "    elif \"_inter_\" in name:\n",
    "        person = name.split(\"_inter_\")[0]\n",
    "    else:\n",
    "        parts = name.rsplit(\"_\", 1)\n",
    "        person = parts[0] if len(parts) == 2 and parts[1].isdigit() else name\n",
    "    \n",
    "    if person in selected_persons:\n",
    "        img = cv2.imread(str(f))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "            # Nouveau nom\n",
    "            idx = sum(1 for x in NEW_DIR.glob(f\"{person}_*.png\")) + 1\n",
    "            new_path = NEW_DIR / f\"{person}_{idx}.png\"\n",
    "            cv2.imwrite(str(new_path), img)\n",
    "            copied += 1\n",
    "\n",
    "print(f\"\\n[OK] {copied} images copiees dans {NEW_DIR}\")\n",
    "\n",
    "# Verifier\n",
    "final_counts = defaultdict(int)\n",
    "for f in NEW_DIR.glob(\"*.png\"):\n",
    "    person = f.stem.rsplit(\"_\", 1)[0]\n",
    "    final_counts[person] += 1\n",
    "\n",
    "print(f\"\\nDataset final:\")\n",
    "for person, count in sorted(final_counts.items()):\n",
    "    print(f\"   {person}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Charger le dataset\n",
    "DATA_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\dataset_top14\")\n",
    "IMG_SIZE = 64\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for filepath in DATA_DIR.glob(\"*.png\"):\n",
    "    person_name = filepath.stem.rsplit(\"_\", 1)[0]\n",
    "    \n",
    "    img = cv2.imread(str(filepath))\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "        labels.append(person_name)\n",
    "\n",
    "images = np.array(images, dtype=np.float32) / 255.0\n",
    "\n",
    "unique_labels = sorted(list(set(labels)))\n",
    "label_to_idx = {name: idx for idx, name in enumerate(unique_labels)}\n",
    "idx_to_label = {idx: name for name, idx in label_to_idx.items()}\n",
    "\n",
    "y = np.array([label_to_idx[name] for name in labels])\n",
    "NUM_CLASSES = len(unique_labels)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET CHARGE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   - Images: {images.shape}\")\n",
    "print(f\"   - Classes: {NUM_CLASSES}\")\n",
    "\n",
    "for idx, name in idx_to_label.items():\n",
    "    count = np.sum(y == idx)\n",
    "    print(f\"   {idx}: {name} ({count} images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_by_class = defaultdict(list)\n",
    "for idx, label in enumerate(y):\n",
    "    indices_by_class[label].append(idx)\n",
    "\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPLIT 80% TRAIN / 20% TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for class_idx in sorted(indices_by_class.keys()):\n",
    "    class_indices = indices_by_class[class_idx].copy()\n",
    "    n_total = len(class_indices)\n",
    "    n_train = int(0.8 * n_total)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(class_indices)\n",
    "    \n",
    "    train_indices.extend(class_indices[:n_train])\n",
    "    test_indices.extend(class_indices[n_train:])\n",
    "    \n",
    "    print(f\"   {idx_to_label[class_idx]}: {n_train} train / {n_total - n_train} test\")\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(train_indices)\n",
    "\n",
    "X_train = images[train_indices]\n",
    "y_train = y[train_indices]\n",
    "X_test = images[test_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "y_train_cat = to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_cat = to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "print(f\"\\n[OK] Train: {X_train.shape[0]} | Test: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN SIMPLE\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODELE CNN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   - Classes: {NUM_CLASSES}\")\n",
    "print(f\"   - Parametres: {model.count_params():,}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENTRAINEMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test, y_test_cat),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train, y_train_cat, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTATS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   - Train Accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"   - Test Accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"   - Overfitting: {(train_acc - test_acc)*100:.2f}%\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train, y_train_cat, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTATS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   - Train Accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"   - Test Accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"   - Overfitting: {(train_acc - test_acc)*100:.2f}%\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(NUM_CLASSES)\n",
    "plt.xticks(tick_marks, [idx_to_label[i][:10] for i in range(NUM_CLASSES)], rotation=45, ha='right')\n",
    "plt.yticks(tick_marks, [idx_to_label[i][:10] for i in range(NUM_CLASSES)])\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "target_names = [idx_to_label[i] for i in range(NUM_CLASSES)]\n",
    "print(classification_report(y_test, y_pred_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 16\n",
    "indices = np.random.choice(len(X_test), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "correct = 0\n",
    "for i, idx in enumerate(indices):\n",
    "    img = X_test[idx]\n",
    "    true_label = idx_to_label[y_test[idx]]\n",
    "    pred_label = idx_to_label[y_pred_classes[idx]]\n",
    "    conf = np.max(y_pred[idx]) * 100\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    \n",
    "    if true_label == pred_label:\n",
    "        color = 'green'\n",
    "        title = f\"OK: {pred_label[:10]}\\n({conf:.0f}%)\"\n",
    "        correct += 1\n",
    "    else:\n",
    "        color = 'red'\n",
    "        title = f\"Pred: {pred_label[:8]}\\nTrue: {true_label[:8]}\"\n",
    "    \n",
    "    axes[i].set_title(title, fontsize=9, color=color)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(f'Predictions: {correct}/{n_samples} correct ({correct/n_samples*100:.0f}%)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 16\n",
    "indices = np.random.choice(len(X_test), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "correct = 0\n",
    "for i, idx in enumerate(indices):\n",
    "    img = X_test[idx]\n",
    "    true_label = idx_to_label[y_test[idx]]\n",
    "    pred_label = idx_to_label[y_pred_classes[idx]]\n",
    "    conf = np.max(y_pred[idx]) * 100\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    \n",
    "    if true_label == pred_label:\n",
    "        color = 'green'\n",
    "        title = f\"OK: {pred_label[:10]}\\n({conf:.0f}%)\"\n",
    "        correct += 1\n",
    "    else:\n",
    "        color = 'red'\n",
    "        title = f\"Pred: {pred_label[:8]}\\nTrue: {true_label[:8]}\"\n",
    "    \n",
    "    axes[i].set_title(title, fontsize=9, color=color)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(f'Predictions: {correct}/{n_samples} correct ({correct/n_samples*100:.0f}%)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUME FINAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "DATASET:\n",
    "   - Images: {len(images)}\n",
    "   - Classes: {NUM_CLASSES}\n",
    "   - Size: {IMG_SIZE}x{IMG_SIZE}\n",
    "\n",
    "SPLIT:\n",
    "   - Train: {len(X_train)} (80%)\n",
    "   - Test: {len(X_test)} (20%)\n",
    "\n",
    "MODEL:\n",
    "   - Conv2D(32) -> Conv2D(64) -> Conv2D(128) -> Dense(512)\n",
    "   - Parameters: {model.count_params():,}\n",
    "\n",
    "RESULTS:\n",
    "   - Train Accuracy: {train_acc*100:.2f}%\n",
    "   - Test Accuracy: {test_acc*100:.2f}%\n",
    "\"\"\")\n",
    "\n",
    "if test_acc >= 0.80:\n",
    "    print(\"EXCELLENT!\")\n",
    "elif test_acc >= 0.60:\n",
    "    print(\"BON!\")\n",
    "elif test_acc >= 0.40:\n",
    "    print(\"MOYEN - peut etre ameliore\")\n",
    "else:\n",
    "    print(\"FAIBLE - verifiez les donnees\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dossier source\n",
    "SOURCE_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\final_clean_dataset\")\n",
    "\n",
    "# Si vide, utiliser le dossier original\n",
    "if not list(SOURCE_DIR.glob(\"*.png\")):\n",
    "    SOURCE_DIR = Path(r\"C:\\Users\\marwa\\OneDrive\\Desktop\\moprh\\2stage_morphed_database_HQ\\stage2_inter_morphs\")\n",
    "\n",
    "files = list(SOURCE_DIR.glob(\"*.png\")) + list(SOURCE_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSE DU DATASET SOURCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dossier: {SOURCE_DIR}\")\n",
    "print(f\"Images: {len(files)}\")\n",
    "\n",
    "# Compter par personne\n",
    "persons = defaultdict(list)\n",
    "for f in files:\n",
    "    name = f.stem\n",
    "    if \"_intra_\" in name:\n",
    "        person = name.split(\"_intra_\")[0]\n",
    "    elif \"_inter_\" in name:\n",
    "        person = name.split(\"_inter_\")[0]\n",
    "    else:\n",
    "        parts = name.rsplit(\"_\", 1)\n",
    "        person = parts[0] if len(parts) == 2 and parts[1].isdigit() else name\n",
    "    persons[person].append(f)\n",
    "\n",
    "print(f\"Personnes detectees: {len(persons)}\")\n",
    "\n",
    "# Afficher distribution\n",
    "print(\"\\nDistribution (top 20):\")\n",
    "for person, files_list in sorted(persons.items(), key=lambda x: -len(x[1]))[:20]:\n",
    "    print(f\"   {person}: {len(files_list)} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
